#### [Jupyter Notebook Link](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/ISU-UP%202021%20WUC%20Project.ipynb)
##### [Data](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/tree/master/data)

## Project Introduction
### What is it?
#### Project Question
*Is there a relationship between financial characteristics and observed challenges as reported by surveyed water user committee members?*

#### Project Goal
To provide data visualization and introductory analysis of survey results from a different, more reproducible perspective that is navigable and can more easily be expanded on.

#### Project Description
Using learned tools from the [ABE](https://www.abe.iastate.edu/) 516X course to observe, visualize, and derive analyses from previously collected survey data. 

### What is it based on?
In the Spring of 2021, I completed a virtual internship with ISU-UP, through my [Global Resource Systems](https://www.globe.iastate.edu/) curriculum, where I assisted in reviewing the current operation and management status of the water user committies affiliates with the program. Uganda requires every community-owned improved water source to have representing community members on a water user committee managing borehole needs. This includes maintaining proper hygiene, attending to repairs, and managing water user fees. In order to continue to improve the communities' clean access to water, there was a need for ISU-UP to investigate certain aspects of water user committees and borehole operations and maintenance. They needed a review of the water user committies and identification of certain challenges they were facing. 

During my short internship, I researched water user committees in Uganda, created and distributed a survey to randomly selected water user committee members across the Kamuli district with affiliated boreholes, received and briefly reviewed the results, and created a written report and oral presentation. 

However, then I knew little regarding data analysis and used the limited tools I had in excel to produce graphs and a summary of respondent information. This project is driven from the lack of sufficient view of data as well as a lack of analysis capabilities, where I sought to "redo" the data visualization and introduce some analysis components into the results. 

### What is ISU-UP and why does this matter?
The [Iowa State University - Uganda Program (ISU-UP)](https://www.globe.iastate.edu/global-experience/extension-projects-uganda/) is a facet of Iowa State University's College of Agriculture and Life Sciences that works in Partnership with Makerere University as well as local instituions in Uganda to operate the [Center for Sustainable Rural Livelihoods (CSRL)](https://www.csrl.cals.iastate.edu/). In coordination since 2003, the CSRL is located in the Kamuli district of rural Uganda and works in tandem with local residents to improve and incorporate sustainable solutions meeting the needs of the community.

ISU-UP has six key programs to support the community: Agronomy & Postharvest, Community Nutrition, Education, Livestock, Entrepreneurship, and WASH. Each program has a series of projects that are dedicated to serving the community. The [WASH](https://www.csrl.cals.iastate.edu/water-sanitation-and-hygiene) program at the CSRL seeks to provide access to sustainable and clean water to the people of the Kamuli district.

![Uganda Map](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/Uganda-map.png)       ![CSRL](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/CSRL_what-we-do.png)

Water Access, Sanitation, and Hygiene programs seek to assist community in obtaining this access to safe drinking water. There are six areas in which WASH operates: make water safe to drink and use, improve hygiene and sanitation, respond to complex internaitonal emergencies and outbreaks, control and eliminate disease, identify adn characterize disease, adn lastly educate and train aboutt WASH. 

To accomplish this mission, ISU-UP has drilled boreholes in the surrounding region that provides sources of safe drinking water and has incorporated sanitation proejcts. This continues to benefit the community by increasing hygiene and awareness to decrease rates of illness and disease. 

This original research and the reimagined results assist ISU-UP in determining the needs of the community and provide clear evidence for future improvements to the WASH program, and by extension, improving the lives of the surrounding community. 

![Children at borehole](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/Borehole-children.png)   ![Water User at borehole](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/Borehole-water-user.png) ![ISU-UP Staff at borehole](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/Borehole-isu-up.png)

## Data
### Collection Method
#### Questionnaire Development
The [questionnaire](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/data/WUC-Survey_S21_cmw.pdf) was based on research, regarding water user committees (WUC) in Uganda, and specified needs ot ISU-UP. For WUCs to be acknowledged, they must develop by-laws, determine and collect water user fees, and supervise the water source. The ISU-UP affiliates WUCs are encouraged to have seven positions (chairperson, vice chairperson, treasurer, secretary, two guards, and a representative of persons with disabilities) and women are expected to hold half of those committee positions. Documentation of households adn water user fees is expected, and having a banking mehtod or documentation is beneficial. The WUCs are expected to conduct some maintenance on the borehole. It was of high interest to ISU-UP to gain insight into the financial components, types of repairs, adn causes of repair needs for the borehole. 

According to the FAO Questionnaire Design guide for formal, standardized surveys, distributed surveys must be identical. They should have the same question order and word choice to provide exposure to the same stimuli in the same order. Particular words should be defined so each participant has the same knowledge for particular questions. The format needs to be accessible and identical for all such that it can be completed quickly, therefore the format of my survey was designed to be printed and used as an interview. 

Parameters, topics, and key questions were outlined into key sections of the survey and then built into questions. In reviewing the questionnaire, questions and jargon were altered to accommodate for the community. Formatting was arranged according to suggestions by Rutgersâ€™s survey preparation guidelines. The final version was reviewed by and sent to the WASH director to then be used for data collection.

![Survey Sections & Example Questions](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/Survey-questions.png)

#### Interviews
Data was intended to be collected from one to three water user committee members from each committee. However, due to travel distance, some water user committees were excluded. An ISU-UP staff member administered the survey via an in-person interview and transcribed the responses. An IRB was not required to purpose given the information is for internal program use only and not publication. Identifiers were included in the surveys to have the ability to ask follow-up questions of specific members. Water user committee identifiers were originally to be included in the survey to analyze the data and provide summaries of each committee. Instead, this piece of information was lacking and therefore acknowledged in the response assessment. 

### What was aquired?
The responses to the questionnaire were handwritten and each survey was scanned and returned to me in individual pdf files. In my original review attempts, I tranferred the answers to each question, as written, to an excel sheet for each response. Through this process, I could already see missing or obscured information, where respondents neglected to answer some questions, survey pages were missing, or the interpretation of the question was different than intended. Some questions were written to review brief, numerical answers. Some questions were written as multiple choice, where the respondents could select yes/no or a/b, etc. Many of the remaining questions were short answer/free response where the intervieww described the conditions of the WUC or the borehole. 

![Example Survey Answers](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/survey-answers.png)

Several of the initial questions asked of interviewees were not relevant to my particular analysis, rather they were intended to provide easy questions to allows the respondent to transition into the questionnaire. The final question, "Additional commentary" was similarly created to provide a transition out of the survey, and was not used for analysis. However, responses to the final question could be applied to other areas of improvement for the program. 

The remaining questions were used as the data input. The more relevant information that I was seeking are those related the the financial characteristics (water user fee, operation and maintenance cost, donations, collection rate), the repairs needed, and the challenges noted by the different respondents. 

### Data Needs
Since the data was originally in a pdf format and crudely converted to excel, the data needed to be reorganized into another excel document before loading into jupyter notebook. For any further downstream analysis, the data needed to be within one excel sheet, with the indeces being the respondents and the columns the question. Questions were referred to by the number rather than description for the sake of abbreviation. 

### Concerns
Much of the collection method was beyond my control and I had limited insight into how the interviews were being conducted, so I had some concerns regarding that process. There were questions within the final version of the survey where I was questioning their relevance or the accuracy of the diction used, but ultimately included them. I was concerned regarding whether the participants would interpret the questions in the same fashion as I intended, and there were some cases where misunderstandings occurred. There were also several responses where the handwriting was illegible, and this the analysis of those responses required more assumptions than others. The more assumptions input into the data, the less reflective they are of the original respondent's perspectives. There was original concern regarding how the multiple short answer questions would be included in the analysis, as there were several different answers combined into a single cell. This was later alleviated by creating a new excel document to reflect the different challenges. 

## Analysis
*Is there a relationship between financial characteristics and observed challenges as reported by surveyed water user committee members?*

### Workflow
To obtain results which answer the project question, the data followed a workflow of pre-processing, data processesing, and conclusions from results. Some of the original workflow intentions were not achieved due to time or data limitations. The analysis process was chosen based on the data needs. Pre-processing in excel was essential to create raw data that was usable for jupyter notebook. The data processing included much data wrangling and text cleaning that organize the data once more into data that could be visualized or analyzed. The data visualization were important to graphically observe the responses and most of which ended in a form originally requested by ISU-UP. The conclusions were formed by statistical assessments (linear regression) or by visual comparisons of the obtained results. 

![Project Workflow](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/workflow.png)

#### Tools used
The following are key class concepts that were integrated into the project:
- loading python packages and data
- reading documentaion
- data wrangling
- descriptive statistics
- machine learning
- data visualization
- text wrangling

### Data Exploration
#### Excel Stuff
As previously mentioned, the original excel file was sufficient for the time, but not for any further analysis. Each participant's survey was initially within an individual excel sheet as the raw data. The summarized data included an excel sheet for the different types of responses. The text responses to challenges, repairs, and successes were thoroughly examined before I identified key terms, categorized information, and then counted response number. 

![Original Excel](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/raw-original.png)
![Excel Responses](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/raw-answers.png)

For use of python in jupyter notebook, all the responses were moved into a table, with some verification needed from the origianl participant's file. The index because respondent number and the columns became the question number. Responses were input as close to the original answer as possible, but with ammendments that allowed the data to be more consistent across responses (e.g. 5000 versus 5000 per house versus 5000 annually versus 5000 per household per year). Again, assumptions regarding responses that were illegible were assumed. 

![Adjusted Excel Data](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/data-usable.png)

#### Data Wrangling
Data wrangling was used to transform the raw data into information where visualizations and comparisions can be made. This required removing blank rows and irrelevant columns, filling in missing values with assumptions, cleaning capitalization, substituting ranges for singular numbers, and adjusting written time measurements as numerical values. These needs were determined after observing: shapes, types, null values, unique columns and answers, and describing the data. 

General set-up and loading data:
```python
#General imports
import pandas as pd
import numpy as np
from scipy import stats

#Visualizations
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()

%matplotlib inline

#Load Data
raw_df = pd.read_excel('E:/ISU/Graduate/Courses/F21/ABE 516X/ISU-UP_RawData.xlsx')
print('DataFrame Shape:', raw_df.shape)
raw_df.head()
```

Example of viewing raw data before wrangling:
```python
#Monitoring and Operation
print('Monitoring', raw_df[13].unique())
print('Mon Freq', raw_df[14].unique())
print('Service Freq', raw_df[15].unique())
print('Repair', raw_df[19].unique())
print('Documentation', raw_df[20.1].unique())
```
![Out-10](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-10.png)

This output showed me the different answers for monitoring (yes, a, b, c, or some combination) that reflected if and how committees monitored the borehole. This output informs that the different combination of answers can be evaluated, but would need to be organized differently beforehand (put into a different dataframe separating out the answers). This also shows the different options for monitoring frequency. Each response can be transformed into number of days or times per year for more straightforward assessments. Nan values are also present among these answers, and are an indication that they either need to be removed or filled with an assumption. Other views of these answers revealed the same answer but under different capitalization conventions, which would need to be altered for consistency later. It also showed some rates where the vocabulary was different but the answer the same (e.g. three times per year versus every four months). Data wrangling allowed for consistency as demonstrated below. 

Dropping irrelevant columns, rows:
```python
#Drop row 8 and columns Respondent, 10.2; reindex
data_df = raw_df.drop(index=8, columns=['Respondent'])
data_df = data_df.reset_index(drop=True)

data_df = data_df.drop(columns=[10.2])
data = data_df.copy()
```

Assumptions (filling in nan or replacing values):
```python
#Task 2 - Deal with assumptions

#10.1: none, nan = no
#11: nan, range = avg value
#12.a.1: nan = no
#12.a.3: range = avg; none = 0
#17: nan = none
#19: nan = b
#20.1: nan = yes

#10.1
data.iloc[2, 13] = 'no'
#11
data.iloc[0, 14] = 65000
data.iloc[18,14] = 75000
data[11].fillna(data[11].mean())
#12.a.1
data['12.a.1'].fillna('no')
#12.a.3
data.iloc[1, 18] = 120000
data.iloc[3, 18] = 90000
data.iloc[4, 18] = 110000
data.iloc[5, 18] = 75000
data.iloc[6, 18] = 70000
data.iloc[7, 18] = 105000
data.iloc[9, 18] = 150000
data.iloc[10, 18] = 105000
data.iloc[11, 18] = 65000
data.iloc[12, 18] = 125000
data.iloc[13, 18] = 75000
data.iloc[15, 18] = 75000
#data['12.a.3'].replace(to_replace='none', value=0)
for r in range (23):
    if data.iloc[r, 18] == 'none':
        data.iloc[r, 18] = 0
#12.a.4
for r in range (23):
    if data.iloc[r, 19] == 'none':
        data.iloc[r, 19] = 'no'
#17
data[17].fillna('none')
#19
data[19].fillna('b')
#20.1
data[20.1].fillna('yes')
```
The above assumptions were based on the knowledge of the data. Question 10.1 matched with question 10.2. If 10.2 was blank or NA, then it was assumed 10.1 was 'no.' Question 17 asked the respondent to describe the most recent borehole breakdown. Some respondents answered with "no major breakdown" which was altered in excel to "none". But some neglected to answer the question and some had this survey page missing, and in those cases I assumed that the answer was also along the lines of no major/reportable breakdown. Question 19 asked who was responsible for repairs and most participants answered "b", which means they hired a local, skilled mechanic to complete the repairs. Since all but one of the responses listed b instead of a (asking a skilled committee member), the assumption was that b would have been the answer. As more assumptions were made in filling or replacing values, the less likely the data would accurately reflect the respondents' true perspectives. 

Addressing capitalization:
```python
print(data[7.1].unique())
```
![Out-15](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-15.png)

```python
wordcol = [1, 2, 3, 5, 7.1, 7.2, 9.1, 10.1, 12, '12.a.4', '12.b.1', '12.b.2', '12.b.3', '12.b.4', '12.b.5', 13, 14, 15, 16, 17, 18, 19, 21, 22, 23]

for c in wordcol:
    data[c] = data[c].str.lower()
print(data[7.1].unique())
print(data['12.a.4'].unique())
```
![Out-16](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-16.png)

Adjusting time inconsistencies and transforming to numerical values:
```python
#Frequencies (training, collection rate, repair, monitoring)
#8 -> x times per year
#12.b.2 -> do x times per year (e.x. monthly = 12, weekly = 52, annually = 1)
#14 -> x times per year
#15 -> x times per year

timecol = [10, 21, 26, 27]

for r in range (23):
    for c in timecol:
        if data.iloc[r, c] == 'once a year' or data.iloc[r, c] == 'yearly' or data.iloc[r, c] == 'annually':
            data.iloc[r, c] = 1
        if data.iloc[r, c] == 'biannually':
            data.iloc[r, c] = 2
        if data.iloc[r, c] == '3 times per year' or data.iloc[r, c] == 'every 4 months':
            data.iloc[r, c] = 3
        if data.iloc[r, c] == '4 times per year' or data.iloc[r, c] == 'every 3 months':
            data.iloc[r, c] = 4
        if data.iloc[r, c] == '6 times per year' or data.iloc[r, c] == 'every 2 months':
            data.iloc[r, c] = 6
        if data.iloc[r, c] == 'monthly':
            data.iloc[r, c] = 12
        if data.iloc[r, c] == 'biweekly':
            data.iloc[r, c] = 26
        if data.iloc[r, c] == 'weekly':
            data.iloc[r, c] = 52
        if data.iloc[r, c] == 'daily':
            data.iloc[r, c] = 365
```
```python
#User Fee
#12.b.1 -> do amount per household per year
data['12.b.1']

#assume row 1 should be 5000 per household per year
#assume row 6 should be 5000 per hoursehold per year

data.iloc[1, 20] = '5000 per household per year'
data.iloc[6, 20] = '5000 per household per year'

for r in range(23):
    if data.iloc[r, 20][-5:] == 'month':
        data['12.b.1'] = data['12.b.1'].str.slice(0, 3)
    else:
        data['12.b.1'] = data['12.b.1'].str.slice(0, 4)
```
```python
#Convert to integers from string
data[[4, '6_women', '6_men', '6_persons-with-disabilities', 9.2, 11, '12.a.3', '12.b.1', '12.b.2', 14, 15]]
data[[4, '6_women', '6_men', '6_persons-with-disabilities', 9.2, 11, '12.a.3', '12.b.1', '12.b.2', 14, 15]] = data[[4, '6_women', '6_men', '6_persons-with-disabilities', 9.2, 11, '12.a.3', '12.b.1', '12.b.2', 14, 15]].apply(pd.to_numeric)

#User fee to annual value
for r in range(23):
    if data.iloc[r, 20] <= 4999:
        data.iloc[r, 20] = (data.iloc[r, 20]) * 12
```
At this point, the data is in a more manageable, consistent, usable form
![data-head](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/data-head.png)

#### Data Visualization
Now that (most of) the data is manageable, it can be graphed in different ways to derive conclusions. This step was done by hand in excel in the previous review attempt, which lead to sufficient, but unclear and not reproducible results. 

Steps for Descriptors & Visualization (reflection of the order of assessment; selected results displayed, for full content see notebook):
1) Numerical Values (overview)
2) WUC Gender Composition (Gender Ratio)  
3) Respondent Position  
4) Training & Meeting Frequency 
5) Household overview  
6) Banking system  
7) Donations 
8) Fees & Collection
9) O&M Cost; Monitoring; Repair  
10) Documentation(s)

WUC Gender Composition:
```python
#Boxplot of WUC and Respondents
data_dem = data[['6_women', '6_men', '6_persons-with-disabilities']]
data_dem

sns.set_theme(palette='terrain', style='ticks')
sns.boxplot(data=data_dem).set(xlabel='WUC Demographic Composition', ylabel='Number of Persons');
```
![Out-25](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-25.png)

```python
#Pie Chart of 50% women
data_dem['Req Met'] = 'yes/no'

for r in range (23):
    if data_dem.iloc[r, 0] >= data_dem.iloc[r, 1]:
        data_dem.iloc[r, 3] = 'yes'
    else:
        data_dem.iloc[r, 3] = 'no'

gender_count = pd.value_counts(data_dem['Req Met'], sort=True)

gender_count.plot(kind='pie', autopct='%1.0f%%', colors=['darkseagreen', 'cadetblue'])
plt.title('Water User Committee Demographics (50%+ women) based on Response');
```
![Out-29](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-29.png)

Conclusion - Most of the water user committees that the respondents represent have sufficient gender ratio. However, with nearly half of the respondents reporting their committees lacking the proper gender ratio, the negligence of meeting the requirement should be addressed. It would be interesting to ask: for what reason(s) are women not sufficiently represented on the water user committee? This might turn out answers relating to those volunteering or stereotypes against women. 

Position of Respondents:
```python
data_pos = data[1].value_counts()
pos_count = pd.value_counts(data[1], sort=True)
pos_count.plot(kind='bar', color='seagreen')
plt.title('Respondent WUC Position')
plt.xlabel('Position')
plt.ylabel('Number of Respondents');
```
![out-32](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-32.png)

Conclusion - Most of the interviewees were chairperson of their respective WUC. My assumption is that they are sufficiently aware of most operations within the committee and are able to provide reliable answers. The treasurers are most likely more aware and knowledgable of the financial characteristics and the guards of monitoring and operation/maintenance needs. It would be interesting to know if the respondent position was related to the types of challenges reported (not observed in this project). 

Training & Meeting Frequency:
```python
meet_f = pd.value_counts(data[8])
meet_f.plot(kind='pie', autopct='%1.0f%%')
plt.title('WUC Meeting Frequency');
```
![out-35](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-35.png)

Household Overview:
```python
#Boxplot (shows range)
users = data[9.2]
sns.boxplot(x=users, palette='ocean').set(xlabel='Number of Households');
```
![out-36](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-36.png)

```python
#Bar Graph (exposes missing data, shows variation)
users.plot(kind='bar', color='navy')
plt.hlines(y=87, xmin=-1, xmax=23, color='olive')
plt.title('Number of Households per Borehole')
plt.xlabel('Respondent')
plt.ylabel('Number of Households');
```
![out-37](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-37.png)

Conclusion - These graphs express the range of number of households retrieving water from the respondent's borehole. It would be interesting to analyze if there is a relationship between the number of households and the types of challenges. For example, do more households have more challenges with sanitation and hygiene? Are boreholes with fewer households stressed financially and service frequency (partially investigated)?

Banking:
```python
bank_count = pd.value_counts(data[10.1])
bank_count.plot(kind='bar', color=['seagreen', 'dodgerblue'])
plt.title('Number of Respondents with Banking System')
plt.ylabel('Number of Respondents');
```
![out-38](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-38.png)

Conclusion - most water user committees do not have a banking system. However, I do not believe this question was well worded or understood by the respondents, and thus the results are not reflective of true occurances. It would be interesting to know if the treasurers are the participants responding yes, and it would also be interesting to have more insight into committees' finance documentation. 

Water User Fees & Collection Rate:
```python
#User Fees
fees_count = pd.value_counts(data['12.b.1'])
fees_count.plot(kind='pie', autopct='%1.0f%%', colors=['cornflowerblue', 'yellowgreen'])
plt.title('Water User Collection Fees (USH) by Number of Respondents');
```
![out-44](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-44.png)

```python
#Collection Rate
collection_count = pd.value_counts(data['12.b.2'])
collection_count.plot(kind='bar', color=['cadetblue', 'darkseagreen', 'steelblue'])
plt.xticks(rotation=90)
plt.title('Water User Fee Collection Rate (collection times per year)')
plt.xlabel('Collections per Year')
plt.ylabel('Number of Respondents');
```
![out-45](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-45.png)

Conclusions - Most water user committees have set a 6000 UGX per household per rate water user fee rate. Just over half of the respondents reported collecting fees annually and just under half reported collecting fees monthly. One respondent claimed fees were collected weekly. It's then interesting to investigate if varying fee collection rates contributed to willingness to pay (investigated) and if fees or collection rates provided different stressors on households. It would be interesting to know how many individuals are in each household, because this can range from 1 to 10 individuals depending on marriage and number of children. 

Frequency of Borehole Service:
```python
service_f = pd.value_counts(data[15])
service_f.plot(kind='pie', autopct='%1.0f%%', colors=['cornflowerblue', 'seagreen', 'yellowgreen'])
plt.title('Percentage of Respondents According to Frequence of Borehole Service');
```
![out-59](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-59.png)

Conclusion - Most respondents service the borehole monthly. Questions that could be derived from this result are: are more repairs required for boreholes serviced less frequently? Are breakdowns less common with boreholes serviced more frequently? Are annual service costs related to frequency of borehole repair? A linear regression was completed to determine if there was a relationship between the frequency of monitoring and the frequency of borehole service (see linear regression). 

Correlation Between Variables:
```python
#Isolated Data
simple_df = data.copy()
simple_df = simple_df[[4, '6_women', '6_men', '6_persons-with-disabilities', 8, 9.2, 11, '12.a.3', '12.b.1', '12.b.2', 14, 15]]

#Heatmap Visualization
simple_corr = simple_df.corr(method='pearson')
sns.heatmap(simple_corr);
```
![out-71](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-71.png)

#### Concerns
To readdressing some of those assumptions, it is worrying that the data used is not a true reflection of respondents due to the missing and assumed data. The assumptions made were based on averages of other responses, based on the knowledge of how a participant answer another question, or my own interpretation of the written answers. At this point in understanding the data, there is also a concern regarding how to complete the text wrangling, visualization, and analysis. 

### Classification & Statistics
#### Supervised Machine Learning
Wanted to practice this skill and used the naive bayes to classify if a WUC met gender ratio requirements (probs can mention that Uganda requires it)

```python
#Review of Naive Bayes Classification (p1)

#X-Variables
X_dem = data_dem[['6_women', '6_men']]
print(X_dem.shape)

#Categories
data_dem['Req_num'] = data_dem['Req Met'].map({'yes':1, 'no':0})
y_dem = data_dem['Req_num']
print(y_dem.shape)

#Import split and NB
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB

#Training & Testing Data
X_train, X_test, y_train, y_test = train_test_split(X_dem, y_dem)
print('X Train Shape:', X_train.shape)
print('y Train Shape:', y_train.shape)

#Training
gnb = GaussianNB()
train = gnb.fit(X_train, y_train)

#Testing
y_pred = train.predict(X_test)
print(y_pred)

print('X Test Shape:', X_test.shape)
print('y Test Shape:', y_test.shape)

#New DataFrame
test = pd.DataFrame(X_test)
test['Req Met'] = y_pred
test.head(5)

#Checking Accuracy
from sklearn import metrics
from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix

print(metrics.accuracy_score(y_test, y_pred))

cm = metrics.confusion_matrix(y_test, y_pred)
cmdf = pd.DataFrame(cm, index = ['No', 'Yes'], columns = ['No', 'Yes'])
print(cmdf)

print(classification_report(y_pred, y_test))

sns.heatmap(cm, annot=True, xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])
plt.title('Heatmap of Naive Bayes Classification, Gender Ratio')
plt.xlabel('True')
plt.ylabel('Predicted');
```
![Out-31](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-31.png)

#### Linear Regression
In wanting to create a way to determine the relationship between different pieces of information, I used an ordinary least squares linear regression, with an outline that is reproducible for other (numerical) answers. 

Demonstrated linear regression for operation and maintenance monitoring and borehole service. The question proposed was: is there a relationship between frequency of monitoring and frequency or borehole service?
```python
#Isolating Data
o_m = data.drop(index=[2, 16, 19, 22])
x_var = o_m[14]
y_var = o_m[15]

#Scatter Plot
plt.scatter(x_var, y_var)
plt.xlabel('Freqeuncy of Monitoring')
plt.ylabel('Frequency of Service');
```
![out-60](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-60.png)

```python
#Linear Regression
import statsmodels.api as sm

o_m_ols = sm.OLS(y_var, x_var)
o_m_reg = o_m_ols.fit()
print('p-value:', o_m_reg.pvalues.loc[14])
print(o_m_reg.summary())
print('Parameters:', o_m_reg.params)
print('R2:', o_m_reg.rsquared)
print('Standard errors:', o_m_reg.bse)
print('Predicted values:', o_m_reg.predict())

om_ols = o_m_reg.get_prediction()
iv_l = om_ols.summary_frame()['obs_ci_lower']
iv_u = om_ols.summary_frame()['obs_ci_upper']

fig, ax = plt.subplots(figsize=(8, 6))

ax.plot(x_var, y_var, 'o', label='Frequency')
ax.plot(x_var, o_m_reg.fittedvalues, 'g--.', label='OLS')
ax.plot(x_var, iv_u, 'r--')
ax.plot(x_var, iv_l, 'r--')
ax.legend(loc='best')
ax.set_xlabel('Frequency of Monitoring')
ax.set_ylabel('Frequency of Service')
```
![out-61a](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-61a.png)
![out-61b](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-61b.png)

Conclusion - There is somewhat of a relationship between service frequency and monitoring frequency. We see that the R^2 value is about 0.6, but there are only 19 observations and several overlapping points. There are several WUCs that monitor at about the same rate of service (which makes sense to save time and human effort). There is still a general conclusion that can be drawn where there is a greater monitoring frequency, there is a likelihood of increased service frequency. Because of this method's greater relevance beyond the project, this activity was created as my class exercise as well. 

### Text Data
#### Cleaning & Wrangling
random test
![out-15](https://user-images.githubusercontent.com/92934572/144771211-7931d081-aab0-4cce-9185-585ed1b5528b.jpg)

test part 2
![out-15](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-15.jpg)

Actual text for this section:
Text cleaning, wrangling, and counting began by created another excel sheet with the "Challenges" presented in a different format. After having many difficulties separating the answers while residing in the same cell, I manually split the answers into Challenge 1-4 in a separate file, with only relevant information for my overall question regarding financial characteristics. While manually organizing the data, I also made additional assumptions regarding the language used to describe the challenges, and replaced similar answers to be written as the same phrase. This would help with counting and viewing the responses. This process required loading in the new file and wrangling the previous data once more. 

```python
#Load Data
challenges_df = pd.read_excel('E:/ISU/Graduate/Courses/F21/ABE 516X/ISU-UP_Challenges.xlsx')
print('DataFrame Shape:', challenges_df.shape)
challenges_df = challenges_df.drop(index=[8], columns=['Respondent'])
challenges_df = challenges_df.reset_index(drop=True)

#11 - O&M Cost
challenges_df.iloc[0, 2] = 65000
challenges_df.iloc[18, 2] = 75000
challenges_df['O&M Cost'].fillna(challenges_df['O&M Cost'].mean())
#12.a.3 - Donations
challenges_df.iloc[1, 3] = 120000
challenges_df.iloc[3, 3] = 90000
challenges_df.iloc[4, 3] = 110000
challenges_df.iloc[5, 3] = 75000
challenges_df.iloc[6, 3] = 70000
challenges_df.iloc[7, 3] = 105000
challenges_df.iloc[9, 3] = 150000
challenges_df.iloc[10, 3] = 105000
challenges_df.iloc[11, 3] = 65000
challenges_df.iloc[12, 3] = 125000
challenges_df.iloc[13, 3] = 75000
challenges_df.iloc[15, 3] = 75000
for r in range (23):
    if challenges_df.iloc[r, 3] == 'none':
        challenges_df.iloc[r, 3] = 0

#Remove capitalized letters
wordcol = ['Training Frequency', 'User Fee', 'Collection Rate', 'Monitoring Rate', 'Service Rate', 'Challenge 1', 'Challenge 2', 'Challenge 3', 'Challenge 4']
for c in wordcol:
    #print(data[c].dtype)
    challenges_df[c] = challenges_df[c].str.lower()

#Adjust time to numerical values
timecol = [0, 5, 6, 7]

for r in range (23):
    for c in timecol:
        if challenges_df.iloc[r, c] == 'once a year' or challenges_df.iloc[r, c] == 'yearly' or challenges_df.iloc[r, c] == 'annually':
            challenges_df.iloc[r, c] = 1
        if challenges_df.iloc[r, c] == 'biannually':
            challenges_df.iloc[r, c] = 2
        if challenges_df.iloc[r, c] == '3 times per year' or challenges_df.iloc[r, c] == 'every 4 months':
            challenges_df.iloc[r, c] = 3
        if challenges_df.iloc[r, c] == '4 times per year' or challenges_df.iloc[r, c] == 'every 3 months':
            challenges_df.iloc[r, c] = 4
        if challenges_df.iloc[r, c] == '6 times per year' or challenges_df.iloc[r, c] == 'every 2 months':
            challenges_df.iloc[r, c] = 6
        if challenges_df.iloc[r, c] == 'monthly':
            challenges_df.iloc[r, c] = 12
        if challenges_df.iloc[r, c] == 'biweekly':
            challenges_df.iloc[r, c] = 26
        if challenges_df.iloc[r, c] == 'weekly':
            challenges_df.iloc[r, c] = 52
        if challenges_df.iloc[r, c] == 'daily':
            challenges_df.iloc[r, c] = 365

#Adjust User Fee
data.iloc[1, 4] = '5000 per household per year'
data.iloc[6, 4] = '5000 per household per year'

for r in range(23):
    if challenges_df.iloc[r, 4][-5:] == 'month':
        challenges_df['User Fee'] = challenges_df['User Fee'].str.slice(0, 3)
    else:
        challenges_df['User Fee'] = challenges_df['User Fee'].str.slice(0, 4)

#Convert from string to integer
challenges_df[['Training Frequency', 'Households', 'O&M Cost', 'Donations', 'User Fee', 'Collection Rate', 'Monitoring Rate', 'Service Rate']] = challenges_df[['Training Frequency', 'Households', 'O&M Cost', 'Donations', 'User Fee', 'Collection Rate', 'Monitoring Rate', 'Service Rate']].apply(pd.to_numeric)
challenges_df.dtypes

#User Fee per Year
for r in range(23):
    if challenges_df.iloc[r, 4] <= 4999:
        challenges_df.iloc[r, 4] = (challenges_df.iloc[r, 4]) * 12
```

The next step was to remove the stop words from the challenges, so that the more common words and phrases would not be influenced by superfluous words. Although there are several different ways to go about removing stop words, I had success in using the gensim package. 
```python
#Required package
%pip install gensim
import gensim
from gensim.parsing.preprocessing import remove_stopwords

#Removing Stop Words
for r in range (23):
    for c in range(8, 12):
        challenges_df.iloc[r, c] = remove_stopwords(challenges_df.iloc[r, c])
```

Word counting was experimented with and prepped to 


Go through this process
outline some code and clarify more assumptions
having to redo the excel thing again

#### Visualization
Describing what word clouds are
showing some code and *wordclouds*
not sure if the other things fit here or in other

#### Determining Relationships
isolating the data and doing the counting stuff

#### Concerns
This is difficult to reproduce because of the way I collected data, and also because of how I managed to put it into excel and python
would have to manipulate the excel file a bit, or create a completely, new one like i did before being able to do any of this stuff
wasn't really clear on text classification before and got lost in the tokenization of things, so I decided to forgo it
This isn't going to be the depth of analysis that I had originally wanted, so the pieces were carefully chosen

## Results
Question: review the project question
Answer: what the result is
### Common Challenges
maybe a thought here, maybe not
#### Different Water User Fee Amount
the code and clear result of this output

#### Different Water User Fee Collection Rate
the code and clear result of this output

### Discussion
thoughts on those results; briefly mention wanting to do more analysis but felt limited by data, knowledge, and time

### Implications
what do the results mean for ISU-UP
my suggestions on what they need to focus on
further research that should be done

## FAIR Principles
define the principles
general discussion of reproducibility
explain how my process meets the principles
explain how my process does not meet the principles
(it'd honestly be great to create a function that would do it all... but i'm really bad at functions)


## Class Exercise
walking classmates through partial wrangling and linear regression 
because this seemed the most useful to other projects
show the code and example output from previously

from Howe: 
In each project, I'd like to see a homework assignment that the class can do/evaluate to learn more about your data.  This should be a reproducible notebook that allows them to learn one or more aspects of your data workflow.  It is also an opportunity to share your research with your colleagues.

## Project Reflection
what did I learn about my data
what did I learn from doing the project
how might i go about doing it differently
what would i have done with more time

# End


# Making the Website

This instruction is specific to the slate theme but should translate well to other themes.  You can change default variables in your website build by making changes in your `_config.yml` file:

```yml
title: [The title of your site]
description: [A short description of your site's purpose]
```

Additionally, you may choose to set the following optional variables:

```yml
show_downloads: ["true" or "false" to indicate whether to provide a download URL]
google_analytics: [Your Google Analytics tracking ID]
```
You can take a look at the `_config.yml` file in this repository to see how to type in the title and description.

### Markdown

You can see this [cheatsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) to work with Markdown language for adding features into this website.  This includes how to add headers, organization (e.g., bullets or lists), tables, and images.  It also includes how to add code to a website.


See example [here](https://github.com/pages-themes/slate/blob/master/index.md).  You can see the raw code also.

#### Relative Links
To create links to other pages, you can read this article:  https://github.blog/2016-12-05-relative-links-for-github-pages/.  Note that these pages should by default direct to the same local folder/directory the index file is.  In this case, my README.md file is my index. If the files are in a different folder, one should specifiy the path for that folder.


Here is an example of a fantastic project website:

https://stephenslab.github.io/ipynb-website/

## Advanced Features

### Stylesheet (Advanced)

If you'd like to add your own custom styles:

1. Create a file called `/assets/css/style.scss` in your site
2. Add the following content to the top of the file, exactly as shown:
    ```scss
    ---
    ---

    @import "{{ site.theme }}";
    ```
3. Add any custom CSS (or Sass, including imports) you'd like immediately after the `@import` line

*Note: If you'd like to change the theme's Sass variables, you must set new values before the `@import` line in your stylesheet.*

### Layouts (Advanced)

If you'd like to change the theme's HTML layout:

1. [Copy the original template](https://github.com/pages-themes/slate/blob/master/_layouts/default.html) from the theme's repository<br />(*Pro-tip: click "raw" to make copying easier*)
2. Create a file called `/_layouts/default.html` in your site
3. Paste the default layout content copied in the first step
4. Customize the layout as you'd like

### Overriding GitHub-generated URLs (Advanced)

Templates often rely on URLs supplied by GitHub such as links to your repository or links to download your project. If you'd like to override one or more default URLs:

1. Look at [the template source](https://github.com/pages-themes/slate/blob/master/_layouts/default.html) to determine the name of the variable. It will be in the form of `{{ site.github.zip_url }}`.
2. Specify the URL that you'd like the template to use in your site's `_config.yml`. For example, if the variable was `site.github.url`, you'd add the following:
    ```yml
    github:
      zip_url: http://example.com/download.zip
      another_url: another value
    ```
3. When your site is built, Jekyll will use the URL you specified, rather than the default one provided by GitHub.

*Note: You must remove the `site.` prefix, and each variable name (after the `github.`) should be indent with two space below `github:`.*

For more information, see [the Jekyll variables documentation](https://jekyllrb.com/docs/variables/).

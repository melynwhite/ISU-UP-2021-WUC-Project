#### [Jupyter Notebook Link](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/ISU-UP%202021%20WUC%20Project.ipynb)
##### [Data](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/tree/master/data)

## Project Introduction
### What is it?
#### Project Question
*Is there a relationship between financial characteristics and observed challenges as reported by surveyed water user committee members?*

#### Project Goal
To provide data visualization and introductory analysis of survey results from a different, more reproducible perspective that is navigable and can more easily be expanded on.

#### Project Description
Using learned tools from the [ABE](https://www.abe.iastate.edu/) 516X course to observe, visualize, and derive analyses from previously collected survey data. 

### What is it based on?
In the Spring of 2021, I completed a virtual internship with ISU-UP, through my [Global Resource Systems](https://www.globe.iastate.edu/) curriculum, where I assisted in reviewing the current operation and management status of the water user committies affiliates with the program. Uganda requires every community-owned improved water source to have representing community members on a water user committee managing borehole needs. This includes maintaining proper hygiene, attending to repairs, and managing water user fees. In order to continue to improve the communities' clean access to water, there was a need for ISU-UP to investigate certain aspects of water user committees and borehole operations and maintenance. They needed a review of the water user committies and identification of certain challenges they were facing. 

During my short internship, I researched water user committees in Uganda, created and distributed a survey to randomly selected water user committee members across the Kamuli district with affiliated boreholes, received and briefly reviewed the results, and created a written report and oral presentation. 

However, then I knew little regarding data analysis and used the limited tools I had in excel to produce graphs and a summary of respondent information. This project is driven from the lack of sufficient view of data as well as a lack of analysis capabilities, where I sought to "redo" the data visualization and introduce some analysis components into the results. 

### What is ISU-UP and why does this matter?
The [Iowa State University - Uganda Program (ISU-UP)](https://www.globe.iastate.edu/global-experience/extension-projects-uganda/) is a facet of Iowa State University's College of Agriculture and Life Sciences that works in Partnership with Makerere University as well as local instituions in Uganda to operate the [Center for Sustainable Rural Livelihoods (CSRL)](https://www.csrl.cals.iastate.edu/). In coordination since 2003, the CSRL is located in the Kamuli district of rural Uganda and works in tandem with local residents to improve and incorporate sustainable solutions meeting the needs of the community.

ISU-UP has six key programs to support the community: Agronomy & Postharvest, Community Nutrition, Education, Livestock, Entrepreneurship, and WASH. Each program has a series of projects that are dedicated to serving the community. The [WASH](https://www.csrl.cals.iastate.edu/water-sanitation-and-hygiene) program at the CSRL seeks to provide access to sustainable and clean water to the people of the Kamuli district.

![Uganda Map](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/Uganda-map.png)       ![CSRL](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/CSRL_what-we-do.png)

Water Access, Sanitation, and Hygiene programs seek to assist community in obtaining this access to safe drinking water. There are six areas in which WASH operates: make water safe to drink and use, improve hygiene and sanitation, respond to complex internaitonal emergencies and outbreaks, control and eliminate disease, identify adn characterize disease, adn lastly educate and train aboutt WASH. 

To accomplish this mission, ISU-UP has drilled boreholes in the surrounding region that provides sources of safe drinking water and has incorporated sanitation proejcts. This continues to benefit the community by increasing hygiene and awareness to decrease rates of illness and disease. 

This original research and the reimagined results assist ISU-UP in determining the needs of the community and provide clear evidence for future improvements to the WASH program, and by extension, improving the lives of the surrounding community. 

![Children at borehole](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/Borehole-children.png)   ![Water User at borehole](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/Borehole-water-user.png) ![ISU-UP Staff at borehole](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/Borehole-isu-up.png)

## Data
### Collection Method
#### Questionnaire Development
The [questionnaire](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/data/WUC-Survey_S21_cmw.pdf) was based on research, regarding water user committees (WUC) in Uganda, and specified needs ot ISU-UP. For WUCs to be acknowledged, they must develop by-laws, determine and collect water user fees, and supervise the water source. The ISU-UP affiliates WUCs are encouraged to have seven positions (chairperson, vice chairperson, treasurer, secretary, two guards, and a representative of persons with disabilities) and women are expected to hold half of those committee positions. Documentation of households adn water user fees is expected, and having a banking mehtod or documentation is beneficial. The WUCs are expected to conduct some maintenance on the borehole. It was of high interest to ISU-UP to gain insight into the financial components, types of repairs, adn causes of repair needs for the borehole. 

According to the FAO Questionnaire Design guide for formal, standardized surveys, distributed surveys must be identical. They should have the same question order and word choice to provide exposure to the same stimuli in the same order. Particular words should be defined so each participant has the same knowledge for particular questions. The format needs to be accessible and identical for all such that it can be completed quickly, therefore the format of my survey was designed to be printed and used as an interview. 

Parameters, topics, and key questions were outlined into key sections of the survey and then built into questions. In reviewing the questionnaire, questions and jargon were altered to accommodate for the community. Formatting was arranged according to suggestions by Rutgersâ€™s survey preparation guidelines. The final version was reviewed by and sent to the WASH director to then be used for data collection.

![Survey Sections & Example Questions](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/Survey-questions.png)

#### Interviews
Data was intended to be collected from one to three water user committee members from each committee. However, due to travel distance, some water user committees were excluded. An ISU-UP staff member administered the survey via an in-person interview and transcribed the responses. An IRB was not required to purpose given the information is for internal program use only and not publication. Identifiers were included in the surveys to have the ability to ask follow-up questions of specific members. Water user committee identifiers were originally to be included in the survey to analyze the data and provide summaries of each committee. Instead, this piece of information was lacking and therefore acknowledged in the response assessment. 

### What was aquired?
The responses to the questionnaire were handwritten and each survey was scanned and returned to me in individual pdf files. In my original review attempts, I tranferred the answers to each question, as written, to an excel sheet for each response. Through this process, I could already see missing or obscured information, where respondents neglected to answer some questions, survey pages were missing, or the interpretation of the question was different than intended. Some questions were written to review brief, numerical answers. Some questions were written as multiple choice, where the respondents could select yes/no or a/b, etc. Many of the remaining questions were short answer/free response where the intervieww described the conditions of the WUC or the borehole. 

![Example Survey Answers](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/survey-answers.png)

Several of the initial questions asked of interviewees were not relevant to my particular analysis, rather they were intended to provide easy questions to allows the respondent to transition into the questionnaire. The final question, "Additional commentary" was similarly created to provide a transition out of the survey, and was not used for analysis. However, responses to the final question could be applied to other areas of improvement for the program. 

The remaining questions were used as the data input. The more relevant information that I was seeking are those related the the financial characteristics (water user fee, operation and maintenance cost, donations, collection rate), the repairs needed, and the challenges noted by the different respondents. 

### Data Needs
Since the data was originally in a pdf format and crudely converted to excel, the data needed to be reorganized into another excel document before loading into jupyter notebook. For any further downstream analysis, the data needed to be within one excel sheet, with the indeces being the respondents and the columns the question. Questions were referred to by the number rather than description for the sake of abbreviation. 

### Concerns & Reflection
Much of the collection method was beyond my control and I had limited insight into how the interviews were being conducted, so I had some concerns regarding that process. There were questions within the final version of the survey where I was questioning their relevance or the accuracy of the diction used, but ultimately included them. I was concerned regarding whether the participants would interpret the questions in the same fashion as I intended, and there were some cases where misunderstandings occurred. There were also several responses where the handwriting was illegible, and this the analysis of those responses required more assumptions than others. The more assumptions input into the data, the less reflective they are of the original respondent's perspectives. There was original concern regarding how the multiple short answer questions would be included in the analysis, as there were several different answers combined into a single cell. This was later alleviated by creating a new excel document to reflect the different challenges. 

## Analysis
*Is there a relationship between financial characteristics and observed challenges as reported by surveyed water user committee members?*

### Workflow
To obtain results which answer the project question, the data followed a workflow of pre-processing, data processesing, and conclusions from results. Some of the original workflow intentions were not achieved due to time or data limitations. The analysis process was chosen based on the data needs. Pre-processing in excel was essential to create raw data that was usable for jupyter notebook. The data processing included much data wrangling and text cleaning that organize the data once more into data that could be visualized or analyzed. The data visualization were important to graphically observe the responses and most of which ended in a form originally requested by ISU-UP. The conclusions were formed by statistical assessments (linear regression) or by visual comparisons of the obtained results. 

![Project Workflow](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/workflow.png)

#### Tools used
The following are key class concepts that were integrated into the project:
- loading python packages and data
- reading documentaion
- data wrangling
- descriptive statistics
- machine learning
- data visualization
- text wrangling

### Data Exploration
#### Excel Stuff
As previously mentioned, the original excel file was sufficient for the time, but not for any further analysis. Each participant's survey was initially within an individual excel sheet as the raw data. The summarized data included an excel sheet for the different types of responses. The text responses to challenges, repairs, and successes were thoroughly examined before I identified key terms, categorized information, and then counted response number. 

![Original Excel](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/raw-original.png)
![Excel Responses](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/raw-answers.png)

For use of python in jupyter notebook, all the responses were moved into a table, with some verification needed from the origianl participant's file. The index because respondent number and the columns became the question number. Responses were input as close to the original answer as possible, but with ammendments that allowed the data to be more consistent across responses (e.g. 5000 versus 5000 per house versus 5000 annually versus 5000 per household per year). Again, assumptions regarding responses that were illegible were assumed. 

![Adjusted Excel Data](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/data-usable.png)

#### Data Wrangling
Data wrangling was used to transform the raw data into information where visualizations and comparisions can be made. This required removing blank rows and irrelevant columns, filling in missing values with assumptions, cleaning capitalization, substituting ranges for singular numbers, and adjusting written time measurements as numerical values. These needs were determined after observing: shapes, types, null values, unique columns and answers, and describing the data. 

General set-up and loading data:
```python
#General imports
import pandas as pd
import numpy as np
from scipy import stats

#Visualizations
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()

%matplotlib inline

#Load Data
raw_df = pd.read_excel('E:/ISU/Graduate/Courses/F21/ABE 516X/ISU-UP_RawData.xlsx')
print('DataFrame Shape:', raw_df.shape)
raw_df.head()
```

Example of viewing raw data before wrangling:
```python
#Monitoring and Operation
print('Monitoring', raw_df[13].unique())
print('Mon Freq', raw_df[14].unique())
print('Service Freq', raw_df[15].unique())
print('Repair', raw_df[19].unique())
print('Documentation', raw_df[20.1].unique())
```
![Out-10](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-10.png)

This output showed me the different answers for monitoring (yes, a, b, c, or some combination) that reflected if and how committees monitored the borehole. This output informs that the different combination of answers can be evaluated, but would need to be organized differently beforehand (put into a different dataframe separating out the answers). This also shows the different options for monitoring frequency. Each response can be transformed into number of days or times per year for more straightforward assessments. Nan values are also present among these answers, and are an indication that they either need to be removed or filled with an assumption. Other views of these answers revealed the same answer but under different capitalization conventions, which would need to be altered for consistency later. It also showed some rates where the vocabulary was different but the answer the same (e.g. three times per year versus every four months). Data wrangling allowed for consistency as demonstrated below. 

Dropping irrelevant columns, rows:
```python
#Drop row 8 and columns Respondent, 10.2; reindex
data_df = raw_df.drop(index=8, columns=['Respondent'])
data_df = data_df.reset_index(drop=True)

data_df = data_df.drop(columns=[10.2])
data = data_df.copy()
```

Assumptions (filling in nan or replacing values):
```python
#Task 2 - Deal with assumptions

#10.1: none, nan = no
#11: nan, range = avg value
#12.a.1: nan = no
#12.a.3: range = avg; none = 0
#17: nan = none
#19: nan = b
#20.1: nan = yes

#10.1
data.iloc[2, 13] = 'no'
#11
data.iloc[0, 14] = 65000
data.iloc[18,14] = 75000
data[11].fillna(data[11].mean())
#12.a.1
data['12.a.1'].fillna('no')
#12.a.3
data.iloc[1, 18] = 120000
data.iloc[3, 18] = 90000
data.iloc[4, 18] = 110000
data.iloc[5, 18] = 75000
data.iloc[6, 18] = 70000
data.iloc[7, 18] = 105000
data.iloc[9, 18] = 150000
data.iloc[10, 18] = 105000
data.iloc[11, 18] = 65000
data.iloc[12, 18] = 125000
data.iloc[13, 18] = 75000
data.iloc[15, 18] = 75000
#data['12.a.3'].replace(to_replace='none', value=0)
for r in range (23):
    if data.iloc[r, 18] == 'none':
        data.iloc[r, 18] = 0
#12.a.4
for r in range (23):
    if data.iloc[r, 19] == 'none':
        data.iloc[r, 19] = 'no'
#17
data[17].fillna('none')
#19
data[19].fillna('b')
#20.1
data[20.1].fillna('yes')
```
The above assumptions were based on the knowledge of the data. Question 10.1 matched with question 10.2. If 10.2 was blank or NA, then it was assumed 10.1 was 'no.' Question 17 asked the respondent to describe the most recent borehole breakdown. Some respondents answered with "no major breakdown" which was altered in excel to "none". But some neglected to answer the question and some had this survey page missing, and in those cases I assumed that the answer was also along the lines of no major/reportable breakdown. Question 19 asked who was responsible for repairs and most participants answered "b", which means they hired a local, skilled mechanic to complete the repairs. Since all but one of the responses listed b instead of a (asking a skilled committee member), the assumption was that b would have been the answer. As more assumptions were made in filling or replacing values, the less likely the data would accurately reflect the respondents' true perspectives. 

Addressing capitalization:
```python
print(data[7.1].unique())
```
![Out-15](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-15.png)

```python
wordcol = [1, 2, 3, 5, 7.1, 7.2, 9.1, 10.1, 12, '12.a.4', '12.b.1', '12.b.2', '12.b.3', '12.b.4', '12.b.5', 13, 14, 15, 16, 17, 18, 19, 21, 22, 23]

for c in wordcol:
    data[c] = data[c].str.lower()
print(data[7.1].unique())
print(data['12.a.4'].unique())
```
![Out-16](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-16.png)

Adjusting time inconsistencies and transforming to numerical values:
```python
#Frequencies (training, collection rate, repair, monitoring)
#8 -> x times per year
#12.b.2 -> do x times per year (e.x. monthly = 12, weekly = 52, annually = 1)
#14 -> x times per year
#15 -> x times per year

timecol = [10, 21, 26, 27]

for r in range (23):
    for c in timecol:
        if data.iloc[r, c] == 'once a year' or data.iloc[r, c] == 'yearly' or data.iloc[r, c] == 'annually':
            data.iloc[r, c] = 1
        if data.iloc[r, c] == 'biannually':
            data.iloc[r, c] = 2
        if data.iloc[r, c] == '3 times per year' or data.iloc[r, c] == 'every 4 months':
            data.iloc[r, c] = 3
        if data.iloc[r, c] == '4 times per year' or data.iloc[r, c] == 'every 3 months':
            data.iloc[r, c] = 4
        if data.iloc[r, c] == '6 times per year' or data.iloc[r, c] == 'every 2 months':
            data.iloc[r, c] = 6
        if data.iloc[r, c] == 'monthly':
            data.iloc[r, c] = 12
        if data.iloc[r, c] == 'biweekly':
            data.iloc[r, c] = 26
        if data.iloc[r, c] == 'weekly':
            data.iloc[r, c] = 52
        if data.iloc[r, c] == 'daily':
            data.iloc[r, c] = 365
```
```python
#User Fee
#12.b.1 -> do amount per household per year
data['12.b.1']

#assume row 1 should be 5000 per household per year
#assume row 6 should be 5000 per hoursehold per year

data.iloc[1, 20] = '5000 per household per year'
data.iloc[6, 20] = '5000 per household per year'

for r in range(23):
    if data.iloc[r, 20][-5:] == 'month':
        data['12.b.1'] = data['12.b.1'].str.slice(0, 3)
    else:
        data['12.b.1'] = data['12.b.1'].str.slice(0, 4)
```
```python
#Convert to integers from string
data[[4, '6_women', '6_men', '6_persons-with-disabilities', 9.2, 11, '12.a.3', '12.b.1', '12.b.2', 14, 15]]
data[[4, '6_women', '6_men', '6_persons-with-disabilities', 9.2, 11, '12.a.3', '12.b.1', '12.b.2', 14, 15]] = data[[4, '6_women', '6_men', '6_persons-with-disabilities', 9.2, 11, '12.a.3', '12.b.1', '12.b.2', 14, 15]].apply(pd.to_numeric)

#User fee to annual value
for r in range(23):
    if data.iloc[r, 20] <= 4999:
        data.iloc[r, 20] = (data.iloc[r, 20]) * 12
```
At this point, the data is in a more manageable, consistent, usable form
![data-head](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/data-head.png)

#### Data Visualization
Now that (most of) the data is manageable, it can be graphed in different ways to derive conclusions. This step was done by hand in excel in the previous review attempt, which lead to sufficient, but unclear and not reproducible results. 

Steps for Descriptors & Visualization (reflection of the order of assessment; selected results displayed, for full content see notebook):
1) Numerical Values (overview)
2) WUC Gender Composition (Gender Ratio)  
3) Respondent Position  
4) Training & Meeting Frequency 
5) Household overview  
6) Banking system  
7) Donations 
8) Fees & Collection
9) O&M Cost; Monitoring; Repair  
10) Documentation(s)

WUC Gender Composition:
```python
#Boxplot of WUC and Respondents
data_dem = data[['6_women', '6_men', '6_persons-with-disabilities']]
data_dem

sns.set_theme(palette='terrain', style='ticks')
sns.boxplot(data=data_dem).set(xlabel='WUC Demographic Composition', ylabel='Number of Persons');
```
![Out-25](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-25.png)

```python
#Pie Chart of 50% women
data_dem['Req Met'] = 'yes/no'

for r in range (23):
    if data_dem.iloc[r, 0] >= data_dem.iloc[r, 1]:
        data_dem.iloc[r, 3] = 'yes'
    else:
        data_dem.iloc[r, 3] = 'no'

gender_count = pd.value_counts(data_dem['Req Met'], sort=True)

gender_count.plot(kind='pie', autopct='%1.0f%%', colors=['darkseagreen', 'cadetblue'])
plt.title('Water User Committee Demographics (50%+ women) based on Response');
```
![Out-29](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-29.png)

Conclusion - Most of the water user committees that the respondents represent have sufficient gender ratio. However, with nearly half of the respondents reporting their committees lacking the proper gender ratio, the negligence of meeting the requirement should be addressed. It would be interesting to ask: for what reason(s) are women not sufficiently represented on the water user committee? This might turn out answers relating to those volunteering or stereotypes against women. 

Position of Respondents:
```python
data_pos = data[1].value_counts()
pos_count = pd.value_counts(data[1], sort=True)
pos_count.plot(kind='bar', color='seagreen')
plt.title('Respondent WUC Position')
plt.xlabel('Position')
plt.ylabel('Number of Respondents');
```
![out-32](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-32.png)

Conclusion - Most of the interviewees were chairperson of their respective WUC. My assumption is that they are sufficiently aware of most operations within the committee and are able to provide reliable answers. The treasurers are most likely more aware and knowledgable of the financial characteristics and the guards of monitoring and operation/maintenance needs. It would be interesting to know if the respondent position was related to the types of challenges reported (not observed in this project). 

Training & Meeting Frequency:
```python
meet_f = pd.value_counts(data[8])
meet_f.plot(kind='pie', autopct='%1.0f%%')
plt.title('WUC Meeting Frequency');
```
![out-35](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-35.png)

Household Overview:
```python
#Boxplot (shows range)
users = data[9.2]
sns.boxplot(x=users, palette='ocean').set(xlabel='Number of Households');
```
![out-36](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-36.png)

```python
#Bar Graph (exposes missing data, shows variation)
users.plot(kind='bar', color='navy')
plt.hlines(y=87, xmin=-1, xmax=23, color='olive')
plt.title('Number of Households per Borehole')
plt.xlabel('Respondent')
plt.ylabel('Number of Households');
```
![out-37](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-37.png)

Conclusion - These graphs express the range of number of households retrieving water from the respondent's borehole. It would be interesting to analyze if there is a relationship between the number of households and the types of challenges. For example, do more households have more challenges with sanitation and hygiene? Are boreholes with fewer households stressed financially and service frequency (partially investigated)?

Banking:
```python
bank_count = pd.value_counts(data[10.1])
bank_count.plot(kind='bar', color=['seagreen', 'dodgerblue'])
plt.title('Number of Respondents with Banking System')
plt.ylabel('Number of Respondents');
```
![out-38](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-38.png)

Conclusion - most water user committees do not have a banking system. However, I do not believe this question was well worded or understood by the respondents, and thus the results are not reflective of true occurances. It would be interesting to know if the treasurers are the participants responding yes, and it would also be interesting to have more insight into committees' finance documentation. 

Water User Fees & Collection Rate:
```python
#User Fees
fees_count = pd.value_counts(data['12.b.1'])
fees_count.plot(kind='pie', autopct='%1.0f%%', colors=['cornflowerblue', 'yellowgreen'])
plt.title('Water User Collection Fees (USH) by Number of Respondents');
```
![out-44](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-44.png)

```python
#Collection Rate
collection_count = pd.value_counts(data['12.b.2'])
collection_count.plot(kind='bar', color=['cadetblue', 'darkseagreen', 'steelblue'])
plt.xticks(rotation=90)
plt.title('Water User Fee Collection Rate (collection times per year)')
plt.xlabel('Collections per Year')
plt.ylabel('Number of Respondents');
```
![out-45](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-45.png)

Conclusions - Most water user committees have set a 6000 UGX per household per rate water user fee rate. Just over half of the respondents reported collecting fees annually and just under half reported collecting fees monthly. One respondent claimed fees were collected weekly. It's then interesting to investigate if varying fee collection rates contributed to willingness to pay (investigated) and if fees or collection rates provided different stressors on households. It would be interesting to know how many individuals are in each household, because this can range from 1 to 10 individuals depending on marriage and number of children. 

Frequency of Borehole Service:
```python
service_f = pd.value_counts(data[15])
service_f.plot(kind='pie', autopct='%1.0f%%', colors=['cornflowerblue', 'seagreen', 'yellowgreen'])
plt.title('Percentage of Respondents According to Frequence of Borehole Service');
```
![out-59](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-59.png)

Conclusion - Most respondents service the borehole monthly. Questions that could be derived from this result are: are more repairs required for boreholes serviced less frequently? Are breakdowns less common with boreholes serviced more frequently? Are annual service costs related to frequency of borehole repair? A linear regression was completed to determine if there was a relationship between the frequency of monitoring and the frequency of borehole service (see linear regression). 

Correlation Between Variables:
```python
#Isolated Data
simple_df = data.copy()
simple_df = simple_df[[4, '6_women', '6_men', '6_persons-with-disabilities', 8, 9.2, 11, '12.a.3', '12.b.1', '12.b.2', 14, 15]]

#Heatmap Visualization
simple_corr = simple_df.corr(method='pearson')
sns.heatmap(simple_corr);
```
![out-71](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-71.png)

#### Concerns & Reflection
To readdressing some of those assumptions, it is worrying that the data used is not a true reflection of respondents due to the missing and assumed data. The assumptions made were based on averages of other responses, based on the knowledge of how a participant answer another question, or my own interpretation of the written answers. At this point in understanding the data, there is also a concern regarding how to complete the text wrangling, visualization, and analysis. 

### Classification & Statistics
#### Supervised Machine Learning
Wanted to practice this skill and used the naive bayes to classify if a WUC met gender ratio requirements (probs can mention that Uganda requires it)

```python
#Review of Naive Bayes Classification (p1)

#X-Variables
X_dem = data_dem[['6_women', '6_men']]
print(X_dem.shape)

#Categories
data_dem['Req_num'] = data_dem['Req Met'].map({'yes':1, 'no':0})
y_dem = data_dem['Req_num']
print(y_dem.shape)

#Import split and NB
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB

#Training & Testing Data
X_train, X_test, y_train, y_test = train_test_split(X_dem, y_dem)
print('X Train Shape:', X_train.shape)
print('y Train Shape:', y_train.shape)

#Training
gnb = GaussianNB()
train = gnb.fit(X_train, y_train)

#Testing
y_pred = train.predict(X_test)
print(y_pred)

print('X Test Shape:', X_test.shape)
print('y Test Shape:', y_test.shape)

#New DataFrame
test = pd.DataFrame(X_test)
test['Req Met'] = y_pred
test.head(5)

#Checking Accuracy
from sklearn import metrics
from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix

print(metrics.accuracy_score(y_test, y_pred))

cm = metrics.confusion_matrix(y_test, y_pred)
cmdf = pd.DataFrame(cm, index = ['No', 'Yes'], columns = ['No', 'Yes'])
print(cmdf)

print(classification_report(y_pred, y_test))

sns.heatmap(cm, annot=True, xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])
plt.title('Heatmap of Naive Bayes Classification, Gender Ratio')
plt.xlabel('True')
plt.ylabel('Predicted');
```
![Out-31](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-31.png)

#### Linear Regression
In wanting to create a way to determine the relationship between different pieces of information, I used an ordinary least squares linear regression, with an outline that is reproducible for other (numerical) answers. 

Demonstrated linear regression for operation and maintenance monitoring and borehole service. The question proposed was: is there a relationship between frequency of monitoring and frequency or borehole service?
```python
#Isolating Data
o_m = data.drop(index=[2, 16, 19, 22])
x_var = o_m[14]
y_var = o_m[15]

#Scatter Plot
plt.scatter(x_var, y_var)
plt.xlabel('Freqeuncy of Monitoring')
plt.ylabel('Frequency of Service');
```
![out-60](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-60.png)

```python
#Linear Regression
import statsmodels.api as sm

o_m_ols = sm.OLS(y_var, x_var)
o_m_reg = o_m_ols.fit()
print('p-value:', o_m_reg.pvalues.loc[14])
print(o_m_reg.summary())
print('Parameters:', o_m_reg.params)
print('R2:', o_m_reg.rsquared)
print('Standard errors:', o_m_reg.bse)
print('Predicted values:', o_m_reg.predict())

om_ols = o_m_reg.get_prediction()
iv_l = om_ols.summary_frame()['obs_ci_lower']
iv_u = om_ols.summary_frame()['obs_ci_upper']

fig, ax = plt.subplots(figsize=(8, 6))

ax.plot(x_var, y_var, 'o', label='Frequency')
ax.plot(x_var, o_m_reg.fittedvalues, 'g--.', label='OLS')
ax.plot(x_var, iv_u, 'r--')
ax.plot(x_var, iv_l, 'r--')
ax.legend(loc='best')
ax.set_xlabel('Frequency of Monitoring')
ax.set_ylabel('Frequency of Service')
```
![out-61a](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-61a.png)
![out-61b](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-61b.png)

Conclusion - There is somewhat of a relationship between service frequency and monitoring frequency. We see that the R^2 value is about 0.6, but there are only 19 observations and several overlapping points. There are several WUCs that monitor at about the same rate of service (which makes sense to save time and human effort). There is still a general conclusion that can be drawn where there is a greater monitoring frequency, there is a likelihood of increased service frequency. Because of this method's greater relevance beyond the project, this activity was created as my class exercise as well. 

### Text Data
#### Cleaning & Wrangling
random test
![out-15](https://user-images.githubusercontent.com/92934572/144771211-7931d081-aab0-4cce-9185-585ed1b5528b.jpg)

test part 2
![out-15](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-15.jpg)

Actual text for this section:
Text cleaning, wrangling, and counting began by created another excel sheet with the "Challenges" presented in a different format. After having many difficulties separating the answers while residing in the same cell, I manually split the answers into Challenge 1-4 in a separate file, with only relevant information for my overall question regarding financial characteristics. While manually organizing the data, I also made additional assumptions regarding the language used to describe the challenges, and replaced similar answers to be written as the same phrase. This would help with counting and viewing the responses. This process required loading in the new file and wrangling the previous data once more. 

```python
#Load Data
challenges_df = pd.read_excel('E:/ISU/Graduate/Courses/F21/ABE 516X/ISU-UP_Challenges.xlsx')
print('DataFrame Shape:', challenges_df.shape)
challenges_df = challenges_df.drop(index=[8], columns=['Respondent'])
challenges_df = challenges_df.reset_index(drop=True)

#11 - O&M Cost
challenges_df.iloc[0, 2] = 65000
challenges_df.iloc[18, 2] = 75000
challenges_df['O&M Cost'].fillna(challenges_df['O&M Cost'].mean())
#12.a.3 - Donations
challenges_df.iloc[1, 3] = 120000
challenges_df.iloc[3, 3] = 90000
challenges_df.iloc[4, 3] = 110000
challenges_df.iloc[5, 3] = 75000
challenges_df.iloc[6, 3] = 70000
challenges_df.iloc[7, 3] = 105000
challenges_df.iloc[9, 3] = 150000
challenges_df.iloc[10, 3] = 105000
challenges_df.iloc[11, 3] = 65000
challenges_df.iloc[12, 3] = 125000
challenges_df.iloc[13, 3] = 75000
challenges_df.iloc[15, 3] = 75000
for r in range (23):
    if challenges_df.iloc[r, 3] == 'none':
        challenges_df.iloc[r, 3] = 0

#Remove capitalized letters
wordcol = ['Training Frequency', 'User Fee', 'Collection Rate', 'Monitoring Rate', 'Service Rate', 'Challenge 1', 'Challenge 2', 'Challenge 3', 'Challenge 4']
for c in wordcol:
    #print(data[c].dtype)
    challenges_df[c] = challenges_df[c].str.lower()

#Adjust time to numerical values
timecol = [0, 5, 6, 7]

for r in range (23):
    for c in timecol:
        if challenges_df.iloc[r, c] == 'once a year' or challenges_df.iloc[r, c] == 'yearly' or challenges_df.iloc[r, c] == 'annually':
            challenges_df.iloc[r, c] = 1
        if challenges_df.iloc[r, c] == 'biannually':
            challenges_df.iloc[r, c] = 2
        if challenges_df.iloc[r, c] == '3 times per year' or challenges_df.iloc[r, c] == 'every 4 months':
            challenges_df.iloc[r, c] = 3
        if challenges_df.iloc[r, c] == '4 times per year' or challenges_df.iloc[r, c] == 'every 3 months':
            challenges_df.iloc[r, c] = 4
        if challenges_df.iloc[r, c] == '6 times per year' or challenges_df.iloc[r, c] == 'every 2 months':
            challenges_df.iloc[r, c] = 6
        if challenges_df.iloc[r, c] == 'monthly':
            challenges_df.iloc[r, c] = 12
        if challenges_df.iloc[r, c] == 'biweekly':
            challenges_df.iloc[r, c] = 26
        if challenges_df.iloc[r, c] == 'weekly':
            challenges_df.iloc[r, c] = 52
        if challenges_df.iloc[r, c] == 'daily':
            challenges_df.iloc[r, c] = 365

#Adjust User Fee
data.iloc[1, 4] = '5000 per household per year'
data.iloc[6, 4] = '5000 per household per year'

for r in range(23):
    if challenges_df.iloc[r, 4][-5:] == 'month':
        challenges_df['User Fee'] = challenges_df['User Fee'].str.slice(0, 3)
    else:
        challenges_df['User Fee'] = challenges_df['User Fee'].str.slice(0, 4)

#Convert from string to integer
challenges_df[['Training Frequency', 'Households', 'O&M Cost', 'Donations', 'User Fee', 'Collection Rate', 'Monitoring Rate', 'Service Rate']] = challenges_df[['Training Frequency', 'Households', 'O&M Cost', 'Donations', 'User Fee', 'Collection Rate', 'Monitoring Rate', 'Service Rate']].apply(pd.to_numeric)
challenges_df.dtypes

#User Fee per Year
for r in range(23):
    if challenges_df.iloc[r, 4] <= 4999:
        challenges_df.iloc[r, 4] = (challenges_df.iloc[r, 4]) * 12
```

The next step was to remove the stop words from the challenges, so that the more common words and phrases would not be influenced by superfluous words. Although there are several different ways to go about removing stop words, I had success in using the gensim package. 
```python
#Required package
%pip install gensim
import gensim
from gensim.parsing.preprocessing import remove_stopwords

#Removing Stop Words
for r in range (23):
    for c in range(8, 12):
        challenges_df.iloc[r, c] = remove_stopwords(challenges_df.iloc[r, c])
```

Word counting was experimented with and prepped to then complete vizualization and determine relationships. 
```python
from collections import Counter
count1 = Counter(challenges_df['Challenge 1']).most_common()
```
![out-76](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-76.jpg)

![out-76](https://user-images.githubusercontent.com/92934572/144773558-661b4c50-1ef1-4543-a76b-c90f13ab496b.jpg)


#### Visualization
Word clouds are a way to visually (more artistically) show text information regarding word frequency. As the word increases in count, and therefore commonality, the font size increases. When viewing word clouds, one is able to see the most frequently used words in a string of text. This is an engaging way to quickly learn about the challenges faced by water user committees as reported by survey participants. 

```python
#Install WordCloud package
%pip install wordcloud
from wordcloud import WordCloud, STOPWORDS

#Challenge 1
text1 = challenges_df['Challenge 1'].values
stopwords1 = set(STOPWORDS)
stopwords1.update(['community', 'failure'])
wordcloud = WordCloud(stopwords=stopwords1).generate(str(text1))
plt.imshow(wordcloud)
plt.axis('off')
plt.show()
```
![out-83](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-83.jpg)

![out-83](https://user-images.githubusercontent.com/92934572/144772407-9f1c9c1a-e24b-44f6-b14a-f9bc0bc9867c.jpg)

The previous word cloud only shows the common words for the responses within the "Challenge 1" column. When converted to lists, the challenges across columns can be combined and then counted for both word clouds and other graphical information. 
```python
#Combining the challenges
list1 = challenges_df['Challenge 1'].astype(str).values.tolist()
list2 = challenges_df['Challenge 2'].astype(str).values.tolist()
list3 = challenges_df['Challenge 3'].astype(str).values.tolist()
list4 = challenges_df['Challenge 4'].astype(str).values.tolist()
combined_list = list1 + list2 + list3 + list4

#Create WordCloud for Combined List
wordcloud = WordCloud(stopwords=stopwords3, background_color='mintcream').generate(str(combined_list))
plt.imshow(wordcloud, interpolation='spline36')
plt.axis('off');
```
![out-87](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-87.jpg)

```python
#Creating Counted list and DataFrame
total_common_list = Counter(combined_list).most_common()
tcl_df = pd.DataFrame.from_dict(total_common_list)
tcl_df = tcl_df.rename(columns={0: "Common Challenges", 1 : "Count"})
tcl_df = tcl_df.drop(index=0)
tcl_df = tcl_df.reset_index(drop=True)

#Bar Graph of Common Challenges
tcl_df.plot(kind='bar', color='darkseagreen')
plt.title('Number of Respondents Identifying Key Challenge')
plt.xlabel('Challenge Type - see key')
plt.ylabel('Number of Respondents');
```
![out-89](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-89.jpg)

#### Determining Relationships
To determine the relationship between financial characteristics and identified challenges, the water user fee and the water user fee collection rate were isolated and then evaluated according to most common challenge. An example of the 6000 UGX water user fee is shown below. For full results, see notebook. For additional, partial results, see the Results section. 
```python
#User Fee = 6000 per year
fee_6000 = challenges_df.copy()

for r in range(23):
    if challenges_df.iloc[r, 4] == 5000:
        fee_6000 = fee_6000.drop(index=r)
fee_6000

#Combining the challenges for 6000
fee6_1 = fee_6000['Challenge 1'].astype(str).values.tolist()
fee6_2 = fee_6000['Challenge 2'].astype(str).values.tolist()
fee6_3 = fee_6000['Challenge 3'].astype(str).values.tolist()
fee6_4 = fee_6000['Challenge 4'].astype(str).values.tolist()
combined_fee6 = fee6_1 + fee6_2 + fee6_3 + fee6_4

#Create WordCloud for 6000 List
stopwords6 = set(STOPWORDS)
stopwords6.update(['community', 'failure', 'borehole'])
wordcloud = WordCloud(stopwords=stopwords6, background_color='mintcream').generate(str(combined_fee6))
plt.imshow(wordcloud, interpolation='spline36')
plt.axis('off');
```
![out-96](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-96.jpg)
```python
#Creating Counted list and DataFrame - User Fee 6000
fee6_list = Counter(combined_fee6).most_common()
fee6_df = pd.DataFrame.from_dict(fee6_list)
fee6_df = fee6_df.rename(columns={0: "Common Challenges", 1 : "Count"})
fee6_df = fee6_df.drop(index=0)
fee6_df = fee6_df.reset_index(drop=True)

#Bar Graph of Common Challenges - user Fee 6000
fee6_df.plot(kind='bar', color='darkseagreen')
plt.title('Number of Respondents Identifying Key Challenges for 6000 UGX Fee')
plt.xlabel('Challenge Type - see key')
plt.ylabel('Number of Respondents');
```
![out-98](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-98.jpg)

#### Concerns & Reflection
This is difficult to reproduce because of the way I collected data, and also because of how I managed to put it into excel and python. Thw excel file would have to be reoganized again to better fit the needs of analysis. My original intention was to perform a text classification, however, I got lost in the tokenization and reverted back to a counting method for observing the text information. Once again, the assumptions made in the process of reorganizing and evaluating the data has the potential to lose the true intention of the participants' responses. Although this method did not result in the intended depth of analysis, the pieces of information used were carefully chosen to still obtain an answer to the original project question, to learn new documentation, and to achieve the project goal. 

## Results
Question: Is there a relationship between financial characteristics and observed challenges as reported by surveyed water user committee members?

Answer: Not really, the most common challenges are consistent across both water user fee quantities and across all water user fee collection rates. 
### Common Challenges
The top four common challenges across all respondents are:
- failure of community members to pay water user fees
- disunity during fee collection
- misunderstandings of and between committee members
- disunity between water user committee members and water users

```python
#Creating Counted list and DataFrame
total_common_list = Counter(combined_list).most_common()
tcl_df = pd.DataFrame.from_dict(total_common_list)
tcl_df = tcl_df.rename(columns={0: "Common Challenges", 1 : "Count"})
tcl_df = tcl_df.drop(index=0)
tcl_df = tcl_df.reset_index(drop=True)
tcl_df
```
![out-88](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-88.jpg)

These results can be broken down into two categories:
- unwillingness of water users to pay fees
- disconnect between water users and committee members

With these overall results, we can then determine how they differ according to financial aspects as recorded by participants. The two examined are: Water User Fee Amount and Water User Fee Collection Rate. 

#### Different Water User Fee Amount
##### 5000 UGX Annual Fee
```python
#Isolating Challenges
fee_5000 = challenges_df.copy()

for r in range(23):
    if challenges_df.iloc[r, 4] == 6000:
        fee_5000 = fee_5000.drop(index=r)
        
#Combining the challenges for 5000
fee5_1 = fee_5000['Challenge 1'].astype(str).values.tolist()
fee5_2 = fee_5000['Challenge 2'].astype(str).values.tolist()
fee5_3 = fee_5000['Challenge 3'].astype(str).values.tolist()
fee5_4 = fee_5000['Challenge 4'].astype(str).values.tolist()
combined_fee5 = fee5_1 + fee5_2 + fee5_3 + fee5_4

#Create WordCloud for 5000 List
stopwords5 = set(STOPWORDS)
stopwords5.update(['community', 'failure', 'borehole'])
wordcloud = WordCloud(stopwords=stopwords5, background_color='mintcream').generate(str(combined_fee5))
plt.imshow(wordcloud, interpolation='spline36')
plt.axis('off');
```
![out-93](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-93.jpg)
```python
#Creating Counted list and DataFrame - User Fee 5000
fee5_list = Counter(combined_fee5).most_common()
fee5_df = pd.DataFrame.from_dict(fee5_list)
fee5_df = fee5_df.rename(columns={0: "Common Challenges", 1 : "Count"})
fee5_df = fee5_df.drop(index=0)
fee5_df = fee5_df.reset_index(drop=True)
fee5_df
```
![out-94](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-94.jpg)
```python
#Bar Graph of Common Challenges - 5000 User Fee
fee5_df.plot(kind='bar', color='darkseagreen')
plt.title('Number of Respondents Identifying Key Challenge for 5000 UGX Fee')
plt.xlabel('Challenge Type - see key')
plt.ylabel('Number of Respondents');
```
![out-95](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-95.jpg)

Note: Most common challenge for respondents with 5000 UGX as the water user fee is failure of the community member to pay their fees, the next being disunity during fee collection

##### 6000 UGX Annual Fee
#User Fee = 6000 per year
```python
fee_6000 = challenges_df.copy()

for r in range(23):
    if challenges_df.iloc[r, 4] == 5000:
        fee_6000 = fee_6000.drop(index=r)
fee_6000

#Combining the challenges for 6000
fee6_1 = fee_6000['Challenge 1'].astype(str).values.tolist()
fee6_2 = fee_6000['Challenge 2'].astype(str).values.tolist()
fee6_3 = fee_6000['Challenge 3'].astype(str).values.tolist()
fee6_4 = fee_6000['Challenge 4'].astype(str).values.tolist()
combined_fee6 = fee6_1 + fee6_2 + fee6_3 + fee6_4

#Create WordCloud for 6000 List
stopwords6 = set(STOPWORDS)
stopwords6.update(['community', 'failure', 'borehole'])
wordcloud = WordCloud(stopwords=stopwords6, background_color='mintcream').generate(str(combined_fee6))
plt.imshow(wordcloud, interpolation='spline36')
plt.axis('off');
```
![out-96](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-96.jpg)
```python
#Creating Counted list and DataFrame - User Fee 6000
fee6_list = Counter(combined_fee6).most_common()
fee6_df = pd.DataFrame.from_dict(fee6_list)
fee6_df = fee6_df.rename(columns={0: "Common Challenges", 1 : "Count"})
fee6_df = fee6_df.drop(index=0)
fee6_df = fee6_df.reset_index(drop=True)
fee6_df
```
![out-97](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-97.jpg)
```python
#Bar Graph of Common Challenges - user Fee 6000
fee6_df.plot(kind='bar', color='darkseagreen')
plt.title('Number of Respondents Identifying Key Challenges for 6000 UGX Fee')
plt.xlabel('Challenge Type - see key')
plt.ylabel('Number of Respondents');
```
![out-98](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-98.jpg)
        
Note: Most common challenge for respondents with 6000 UGX as the water user fee is failure of the community member to pay their fees, disunity during fee collection, and misunderstandings of or between committee members. I think because there are more Respondents reporting a 6000 UGX annual water user fee, that there are simply more responses for challenges.

#### Different Water User Fee Collection Rate
```python
#Same Comparison process, but with collection rate
challenges_df['Collection Rate'].unique()

#Collection Rate Challenges

#Collection Rate - Weekly
#Isolation
rate_52 = challenges_df.copy()
for r in range(23):
    if challenges_df.iloc[r, 5] == 12:
        rate_52 = rate_52.drop(index=r)
    if challenges_df.iloc[r, 5] == 1:
        rate_52 = rate_52.drop(index=r)
#Combination
rate52_1 = rate_52['Challenge 1'].astype(str).values.tolist()
rate52_2 = rate_52['Challenge 2'].astype(str).values.tolist()
rate52_3 = rate_52['Challenge 3'].astype(str).values.tolist()
rate52_4 = rate_52['Challenge 4'].astype(str).values.tolist()
combined_rate52 = rate52_1 + rate52_2 + rate52_3 + rate52_4
#WordCloud
stopwords = set(STOPWORDS)
stopwords.update(['community', 'failure', 'borehole'])
wordcloud52 = WordCloud(stopwords=stopwords, background_color='mintcream').generate(str(combined_rate52))
#Counted List & DataFrame
rate52_list = Counter(combined_fee6).most_common()
rate52_df = pd.DataFrame.from_dict(rate52_list)
rate52_df = rate52_df.rename(columns={0: "Common Challenges", 1 : "Count"})
rate52_df = rate52_df.drop(index=0)
rate52_df = rate52_df.reset_index(drop=True)

#Collection Rate - Monthly
#Isolation
rate_12 = challenges_df.copy()
for r in range(23):
    if challenges_df.iloc[r, 5] == 52:
        rate_12 = rate_12.drop(index=r)
    if challenges_df.iloc[r, 5] == 1:
        rate_12 = rate_12.drop(index=r)
#Combination
rate12_1 = rate_12['Challenge 1'].astype(str).values.tolist()
rate12_2 = rate_12['Challenge 2'].astype(str).values.tolist()
rate12_3 = rate_12['Challenge 3'].astype(str).values.tolist()
rate12_4 = rate_12['Challenge 4'].astype(str).values.tolist()
combined_rate12 = rate12_1 + rate12_2 + rate12_3 + rate12_4
#WordCloud
wordcloud12 = WordCloud(stopwords=stopwords, background_color='mintcream').generate(str(combined_rate12))
#Counted List & DataFrame
rate12_list = Counter(combined_rate12).most_common()
rate12_df = pd.DataFrame.from_dict(rate12_list)
rate12_df = rate12_df.rename(columns={0: "Common Challenges", 1 : "Count"})
rate12_df = rate12_df.drop(index=0)
rate12_df = rate12_df.reset_index(drop=True)

#Collection Rate - Annually
#Isolation
rate_1 = challenges_df.copy()
for r in range(23):
    if challenges_df.iloc[r, 5] == 52:
        rate_1 = rate_1.drop(index=r)
    if challenges_df.iloc[r, 5] == 12:
        rate_1 = rate_1.drop(index=r)
#Combination
rate1_1 = rate_1['Challenge 1'].astype(str).values.tolist()
rate1_2 = rate_1['Challenge 2'].astype(str).values.tolist()
rate1_3 = rate_1['Challenge 3'].astype(str).values.tolist()
rate1_4 = rate_1['Challenge 4'].astype(str).values.tolist()
combined_rate1 = rate1_1 + rate1_2 + rate1_3 + rate1_4
#WordCloud
wordcloud1 = WordCloud(stopwords=stopwords, background_color='mintcream').generate(str(combined_rate1))
#Counted List & DataFrame
rate1_list = Counter(combined_rate1).most_common()
rate1_df = pd.DataFrame.from_dict(rate1_list)
rate1_df = rate1_df.rename(columns={0: "Common Challenges", 1 : "Count"})
rate1_df = rate1_df.drop(index=0)
rate1_df = rate1_df.reset_index(drop=True)
```
##### Weekly Collection Rate
```python
#Weekly Collection Rate WordCloud
plt.imshow(wordcloud52, interpolation='spline36')
plt.axis('off');
```
![out-101](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-101.jpg)
```python
#Weekly Collection Rate Challenges
rate52_df
```
![out-102](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-102.jpg)
```python
#Bar Graph of Common Challenges - Weekly
rate52_df.plot(kind='bar', color='darkseagreen')
plt.title('Number of Respondents Identifying Key Challenges for Weekly Collection Rate')
plt.xlabel('Challenge Type - see key')
plt.ylabel('Number of Respondents');
```
![out-103](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-103.jpg)

##### Monthly Collection Rate
```python
#Monthly Collection Rate WordCloud
plt.imshow(wordcloud12, interpolation='spline36')
plt.axis('off');
```
![out-104](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-104.jpg)
```python
#Monthly Collection Rate Challenges
rate12_df
```
![out-105](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-105.jpg)
```python
#Bar Graph of Common Challenges - Monthly
rate12_df.plot(kind='bar', color='darkseagreen')
plt.title('Number of Respondents Identifying Key Challenge for Monthly Collection Rate')
plt.xlabel('Challenge Type - see key')
plt.ylabel('Number of Respondents');
```
![out-106](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-106.jpg)

##### Annual Collection Rate
```python
#Annual Collection Rate WordCloud
plt.imshow(wordcloud1, interpolation='spline36')
plt.axis('off');
```
![out-107](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-107.jpg)
```python
#Annual Collection Rate Challenges
rate1_df
```
![out=108](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-108.jpg)
```python
#Bar Graph of Common Challenges - Annual
rate1_df.plot(kind='bar', color='darkseagreen')
plt.title('Number of Respondents Identifying Key Challenge for Annual Collection Rate')
plt.xlabel('Challenge Type - see key')
plt.ylabel('Number of Respondents');
```
![out-109](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-109.jpg)

### Discussion
Challenges, regardless of the water user fee or the collection rate, remain consistently an unwillingness of the water user to pay the fee. This is demonstrated by "disunity during fee collection" and "failure of community members to pay fees" being one of the highest counted challenges. Misunderstandings of the committee members is also a frequent challenge reported among respondents. Although more analysis was desired, the project and subsequent results was limited by data, knowledge, and time. 

### Implications
Challenges are largely participatory in nature, with disunity in payment collection, disrespect of water user committee members and disunity or failure in cleaning the borehole. Another challenge is water users failing to pay or delaying their fee payment. A slight majority of responses claimed that at least half of the committee members were women. The committee position of â€˜representative of persons with disabilitiesâ€™ is incorporated in the committees, however very few have this position filled. 

The next step in this project is further statistical analysis of the responses, determining correlation between needed repairs and the causes within the responses, the impact of those needed repairs on challenges, and the influence of training and committee demographics on success. This information can provide numerical justification for areas of program development. Based on the responses, it can be concluded that additional advocacy for women and persons with disabilities on committees is needed for representation. Many responses included participatory challenges, which is commonly across community-based water distribution schemes around the world, but is also an area that can be further investigated. The causes of this disunity in the community were not investigated and could be another point for future consideration. 

## FAIR Principles
define the principles
general discussion of reproducibility
explain how my process meets the principles
explain how my process does not meet the principles
(it'd honestly be great to create a function that would do it all... but i'm really bad at functions)

## [Class Exercise](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/ISU-UP%202021%20WUC%20Project%20-%20Class%20Exercise.ipynb)
The goal of the exercise is to review the data wrangling process for this data and to complete an OLS linear regression on two variables of choice.
An abbreviated version of the guided code is below:

```python
#Linear Regression (part 1)
#Using linear regression analysis as the method to determine if there is a relationship
#We are not asking if there are differences in points, just determining if there exists trends
#Using Ordinary Least Squares because we are assuming homoscedasticity and no autocorrelation (all points independent with no delay)
#Would use Generalized Least Squares (GLS) should heteroscedasticity or autocorrelation be true

#Isolating the Data
isolated_df = data.copy() #create a copy of the wrangled DataFrame; rename isolated_df according to desired variables
isolated_df = isolated_df[[15, '12.b.2']] #choose the two variables that you wish to evaluate
isolated_df = isolated_df.dropna() #drop with missing values, as they cannot be evaluated
isolated_df = isolated_df.reset_index(drop=True) #reset the index after dropping values

isolated_df #check the DataFrame to verify chosen variables

#Creating x and Y variables
x_variable = isolated_df[15] #choose the column of your x-variable
y_variable = isolated_df['12.b.2'] #choose the column of your y-variable

#Scatter Plot
plt.scatter(x_variable, y_variable)
plt.title('Title of Scatter Plot')
plt.xlabel('X Axis Label')
plt.ylabel('Y Axis Label');
```
```python
#Linear Regression (part 2)

#Import Statistics Package
import statsmodels.api as sm

#Ordinary Least Squares Regression
isolated_ols = sm.OLS(y_variable, x_variable)
isolated_reg = isolated_ols.fit()

#Parameters for Evaluation of the fit
print('p-value:', isolated_reg.pvalues.loc[15]) #the p-values will use the length of the x-variable
print('Parameters:', isolated_reg.params)
print('R2:', isolated_reg.rsquared)
print('Standard errors:', isolated_reg.bse)
print('Predicted values:', isolated_reg.predict())
print(isolated_reg.summary())

#Visualizing the fit
#establishing the confidence intervals
isolated_pred = isolated_reg.get_prediction()
iv_l = isolated_pred.summary_frame()['obs_ci_lower'] #lower confidence interval line
iv_u = isolated_pred.summary_frame()['obs_ci_upper'] #upper confidence internal line
#plotting the results
fig, ax = plt.subplots(figsize=(8, 6)) #size of the graph
ax.plot(x_variable, y_variable, 'o', label='Frequency') #scatter plot of points
ax.plot(x_variable, isolated_reg.fittedvalues, 'g--.', label='OLS') #best fit line
ax.plot(x_variable, iv_u, 'r--') #upper ci
ax.plot(x_variable, iv_l, 'r--') #lower ci
ax.legend(loc='best') #legend location
ax.set_title('Graph Title')
ax.set_xlabel('X Axis Label')
ax.set_ylabel('Y Axis Label');
```
# End

### Markdown

You can see this [cheatsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) to work with Markdown language for adding features into this website.  This includes how to add headers, organization (e.g., bullets or lists), tables, and images.  It also includes how to add code to a website.


See example [here](https://github.com/pages-themes/slate/blob/master/index.md).  You can see the raw code also.

#### Relative Links
To create links to other pages, you can read this article:  https://github.blog/2016-12-05-relative-links-for-github-pages/.  Note that these pages should by default direct to the same local folder/directory the index file is.  In this case, my README.md file is my index. If the files are in a different folder, one should specifiy the path for that folder.


Here is an example of a fantastic project website:

https://stephenslab.github.io/ipynb-website/

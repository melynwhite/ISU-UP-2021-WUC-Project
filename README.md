#### [Jupyter Notebook Link](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/ISU-UP%202021%20WUC%20Project.ipynb)
##### [Data](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/tree/master/data)

## Project Introduction
### What is it?
#### Project Question
*Is there a relationship between financial characteristics and observed challenges as reported by surveyed water user committee members?*

#### Project Goal
To provide data visualization and introductory analysis of survey results from a different, more reproducible perspective that is navigable and can more easily be expanded on.

#### Project Description
Using learned tools from the [ABE](https://www.abe.iastate.edu/) 516X course to observe, visualize, and derive analyses from previously collected survey data. 

### What is it based on?
In the Spring of 2021, I completed a virtual internship with ISU-UP, through my [Global Resource Systems](https://www.globe.iastate.edu/) curriculum, where I assisted in reviewing the current operation and management status of the water user committies affiliates with the program. Uganda requires every community-owned improved water source to have representing community members on a water user committee managing borehole needs. This includes maintaining proper hygiene, attending to repairs, and managing water user fees. In order to continue to improve the communities' clean access to water, there was a need for ISU-UP to investigate certain aspects of water user committees and borehole operations and maintenance. They needed a review of the water user committies and identification of certain challenges they were facing. 

During my short internship, I researched water user committees in Uganda, created and distributed a survey to randomly selected water user committee members across the Kamuli district with affiliated boreholes, received and briefly reviewed the results, and created a written report and oral presentation. 

However, then I knew little regarding data analysis and used the limited tools I had in excel to produce graphs and a summary of respondent information. This project is driven from the lack of sufficient view of data as well as a lack of analysis capabilities, where I sought to "redo" the data visualization and introduce some analysis components into the results. 

### What is ISU-UP and why does this matter?
The [Iowa State University - Uganda Program (ISU-UP)](https://www.globe.iastate.edu/global-experience/extension-projects-uganda/) is a facet of Iowa State University's College of Agriculture and Life Sciences that works in Partnership with Makerere University as well as local instituions in Uganda to operate the [Center for Sustainable Rural Livelihoods (CSRL)](https://www.csrl.cals.iastate.edu/). In coordination since 2003, the CSRL is located in the Kamuli district of rural Uganda and works in tandem with local residents to improve and incorporate sustainable solutions meeting the needs of the community.

ISU-UP has six key programs to support the community: Agronomy & Postharvest, Community Nutrition, Education, Livestock, Entrepreneurship, and WASH. Each program has a series of projects that are dedicated to serving the community. The [WASH](https://www.csrl.cals.iastate.edu/water-sanitation-and-hygiene) program at the CSRL seeks to provide access to sustainable and clean water to the people of the Kamuli district.

![Uganda Map](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/Uganda-map.png)       ![CSRL](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/CSRL_what-we-do.png)

Water Access, Sanitation, and Hygiene programs seek to assist community in obtaining this access to safe drinking water. There are six areas in which WASH operates: make water safe to drink and use, improve hygiene and sanitation, respond to complex internaitonal emergencies and outbreaks, control and eliminate disease, identify adn characterize disease, adn lastly educate and train aboutt WASH. 

To accomplish this mission, ISU-UP has drilled boreholes in the surrounding region that provides sources of safe drinking water and has incorporated sanitation proejcts. This continues to benefit the community by increasing hygiene and awareness to decrease rates of illness and disease. 

This original research and the reimagined results assist ISU-UP in determining the needs of the community and provide clear evidence for future improvements to the WASH program, and by extension, improving the lives of the surrounding community. 

![Children at borehole](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/Borehole-children.png)   ![Water User at borehole](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/Borehole-water-user.png) ![ISU-UP Staff at borehole](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/Borehole-isu-up.png)

## Data
### Collection Method
#### Questionnaire Development
The questionnaire was based on research, regarding water user committees (WUC) in Uganda, and specified needs ot ISU-UP. For WUCs to be acknowledged, they must develop by-laws, determine and collect water user fees, and supervise the water source. The ISU-UP affiliates WUCs are encouraged to have seven positions (chairperson, vice chairperson, treasurer, secretary, two guards, and a representative of persons with disabilities) and women are expected to hold half of those committee positions. Documentation of households adn water user fees is expected, and having a banking mehtod or documentation is beneficial. The WUCs are expected to conduct some maintenance on the borehole. It was of high interest to ISU-UP to gain insight into the financial components, types of repairs, adn causes of repair needs for the borehole. 

According to the FAO Questionnaire Design guide for formal, standardized surveys, distributed surveys must be identical. They should have the same question order and word choice to provide exposure to the same stimuli in the same order. Particular words should be defined so each participant has the same knowledge for particular questions. The format needs to be accessible and identical for all such that it can be completed quickly, therefore the format of my survey was designed to be printed and used as an interview. 

Parameters, topics, and key questions were outlined into key sections of the survey and then built into questions. In reviewing the questionnaire, questions and jargon were altered to accommodate for the community. Formatting was arranged according to suggestions by Rutgersâ€™s survey preparation guidelines. The final version was reviewed by and sent to the WASH director to then be used for data collection.

#### Interviews
Data was intended to be collected from one to three water user committee members from each committee. However, due to travel distance, some water user committees were excluded. An ISU-UP staff member administered the survey via an in-person interview and transcribed the responses. An IRB was not required to purpose given the information is for internal program use only and not publication. Identifiers were included in the surveys to have the ability to ask follow-up questions of specific members. Water user committee identifiers were originally to be included in the survey to analyze the data and provide summaries of each committee. Instead, this piece of information was lacking and therefore acknowledged in the response assessment. 

![Survey Sections & Example Questions](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/Survey-questions.png)

### What was aquired?
The responses to the questionnaire were handwritten and each survey was scanned and returned to me in individual pdf files. In my original review attempts, I tranferred the answers to each question, as written, to an excel sheet for each response. Through this process, I could already see missing or obscured information, where respondents neglected to answer some questions, survey pages were missing, or the interpretation of the question was different than intended. Some questions were written to review brief, numerical answers. Some questions were written as multiple choice, where the respondents could select yes/no or a/b, etc. Many of the remaining questions were short answer/free response where the intervieww described the conditions of the WUC or the borehole. 

![Example Survey Answers](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/survey-answers.png)

Several of the initial questions asked of interviewees were not relevant to my particular analysis, rather they were intended to provide easy questions to allows the respondent to transition into the questionnaire. The final question, "Additional commentary" was similarly created to provide a transition out of the survey, and was not used for analysis. However, responses to the final question could be applied to other areas of improvement for the program. 

The remaining questions were used as the data input. The more relevant information that I was seeking are those related the the financial characteristics (water user fee, operation and maintenance cost, donations, collection rate), the repairs needed, and the challenges noted by the different respondents. 

### Data Needs
Since the data was originally in a pdf format and crudely converted to excel, the data needed to be reorganized into another excel document before loading into jupyter notebook. For any further downstream analysis, the data needed to be within one excel sheet, with the indeces being the respondents and the columns the question. Questions were referred to by the number rather than description for the sake of abbreviation. 

### Concerns
Much of the collection method was beyond my control and I had limited insight into how the interviews were being conducted, so I had some concerns regarding that process. There were questions within the final version of the survey where I was questioning their relevance or the accuracy of the diction used, but ultimately included them. I was concerned regarding whether the participants would interpret the questions in the same fashion as I intended, and there were some cases where misunderstandings occurred. There were also several responses where the handwriting was illegible, and this the analysis of those responses required more assumptions than others. The more assumptions input into the data, the less reflective they are of the original respondent's perspectives. There was original concern regarding how the multiple short answer questions would be included in the analysis, as there were several different answers combined into a single cell. This was later alleviated by creating a new excel document to reflect the different challenges. 

## Analysis
The project question asks: *Is there a relationship between financial characteristics and observed challenges as reported by surveyed water user committee members?*

### Workflow
To obtain results which answer the project question, the data followed a workflow of pre-processing, data processesing, and conclusions from results. Some of the original workflow intentions were not achieved due to time or data limitations. The analysis process was chosen based on the data needs. Pre-processing in excel was essential to create raw data that was usable for jupyter notebook. The data processing included much data wrangling and text cleaning that organize the data once more into data that could be visualized or analyzed. The data visualization were important to graphically observe the responses and most of which ended in a form originally requested by ISU-UP. The conclusions were formed by statistical assessments (linear regression) or by visual comparisons of the obtained results. 

![Project Workflow](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/workflow.png)
#### Tools used
The following are key class concepts that were integrated into the project:
- loading python packages and data
- reading documentaion
- data wrangling
- descriptive statistics
- machine learning
- data visualization
- text wrangling

### Data Exploration
#### Excel Stuff
As previously mentioned, the original excel file was sufficient for the time, but not for any further analysis. Each participant's survey was initially within an individual excel sheet as the raw data. The summarized data included an excel sheet for the different types of responses. The text responses to challenges, repairs, and successes were thoroughly examined before I identified key terms, categorized information, and then counted response number. 

![Original Excel](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/raw-original.png)
![Excel Responses](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/raw-answers.png)

For use of python in jupyter notebook, all the responses were moved into a table, with some verification needed from the origianl participant's file. The index because respondent number and the columns became the question number. Responses were input as close to the original answer as possible, but with ammendments that allowed the data to be more consistent across responses (e.g. 5000 versus 5000 per house versus 5000 annually versus 5000 per household per year). Again, assumptions regarding responses that were illegible were assumed. 

![Adjusted Excel Data](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/data-usable.png)

#### Data Wrangling
Data wrangling was used to transform the raw data into information where visualizations and comparisions can be made. This required removing blank rows and irrelevant columns, filling in missing values with assumptions, cleaning capitalization, substituting ranges for singular numbers, and adjusting written time measurements as numerical values. These needs were determined after observing: shapes, types, null values, unique columns and answers, and describing the data. 

General set-up and loading data:
```python
#General imports
import pandas as pd
import numpy as np
from scipy import stats

#Visualizations
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()

%matplotlib inline

#Load Data
raw_df = pd.read_excel('E:/ISU/Graduate/Courses/F21/ABE 516X/ISU-UP_RawData.xlsx')
print('DataFrame Shape:', raw_df.shape)
raw_df.head()
```

Example of viewing raw data before wrangling:
```python
#Monitoring and Operation
print('Monitoring', raw_df[13].unique())
print('Mon Freq', raw_df[14].unique())
print('Service Freq', raw_df[15].unique())
print('Repair', raw_df[19].unique())
print('Documentation', raw_df[20.1].unique())
```
![Out-10](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-10.png)

This output showed me the different answers for monitoring (yes, a, b, c, or some combination) that reflected if and how committees monitored the borehole. This output informs that the different combination of answers can be evaluated, but would need to be organized differently beforehand (put into a different dataframe separating out the answers). This also shows the different options for monitoring frequency. Each response can be transformed into number of days or times per year for more straightforward assessments. Nan values are also present among these answers, and are an indication that they either need to be removed or filled with an assumption. Other views of these answers revealed the same answer but under different capitalization conventions, which would need to be altered for consistency later. It also showed some rates where the vocabulary was different but the answer the same (e.g. three times per year versus every four months). Data wrangling allowed for consistency as demonstrated below. 

Dropping irrelevant columns, rows:
```python
#Drop row 8 and columns Respondent, 10.2; reindex
data_df = raw_df.drop(index=8, columns=['Respondent'])
data_df = data_df.reset_index(drop=True)

data_df = data_df.drop(columns=[10.2])
data = data_df.copy()
```

Assumptions (filling in nan or replacing values):
```python
#Task 2 - Deal with assumptions

#10.1: none, nan = no
#11: nan, range = avg value
#12.a.1: nan = no
#12.a.3: range = avg; none = 0
#17: nan = none
#19: nan = b
#20.1: nan = yes

#10.1
data.iloc[2, 13] = 'no'
#11
data.iloc[0, 14] = 65000
data.iloc[18,14] = 75000
data[11].fillna(data[11].mean())
#12.a.1
data['12.a.1'].fillna('no')
#12.a.3
data.iloc[1, 18] = 120000
data.iloc[3, 18] = 90000
data.iloc[4, 18] = 110000
data.iloc[5, 18] = 75000
data.iloc[6, 18] = 70000
data.iloc[7, 18] = 105000
data.iloc[9, 18] = 150000
data.iloc[10, 18] = 105000
data.iloc[11, 18] = 65000
data.iloc[12, 18] = 125000
data.iloc[13, 18] = 75000
data.iloc[15, 18] = 75000
#data['12.a.3'].replace(to_replace='none', value=0)
for r in range (23):
    if data.iloc[r, 18] == 'none':
        data.iloc[r, 18] = 0
#12.a.4
for r in range (23):
    if data.iloc[r, 19] == 'none':
        data.iloc[r, 19] = 'no'
#17
data[17].fillna('none')
#19
data[19].fillna('b')
#20.1
data[20.1].fillna('yes')
```
The above assumptions were based on the knowledge of the data. Question 10.1 matched with question 10.2. If 10.2 was blank or NA, then it was assumed 10.1 was 'no.' Question 17 asked the respondent to describe the most recent borehole breakdown. Some respondents answered with "no major breakdown" which was altered in excel to "none". But some neglected to answer the question and some had this survey page missing, and in those cases I assumed that the answer was also along the lines of no major/reportable breakdown. Question 19 asked who was responsible for repairs and most participants answered "b", which means they hired a local, skilled mechanic to complete the repairs. Since all but one of the responses listed b instead of a (asking a skilled committee member), the assumption was that b would have been the answer. As more assumptions were made in filling or replacing values, the less likely the data would accurately reflect the respondents' true perspectives. 

Addressing capitalization:
```python
print(data[7.1].unique())
```
![Out-15](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-15.png)

```python
wordcol = [1, 2, 3, 5, 7.1, 7.2, 9.1, 10.1, 12, '12.a.4', '12.b.1', '12.b.2', '12.b.3', '12.b.4', '12.b.5', 13, 14, 15, 16, 17, 18, 19, 21, 22, 23]

for c in wordcol:
    data[c] = data[c].str.lower()
print(data[7.1].unique())
print(data['12.a.4'].unique())
```
![Out-16](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/out-16.png)

Adjusting time inconsistencies and transforming to numerical values:
```python
#Frequencies (training, collection rate, repair, monitoring)
#8 -> x times per year
#12.b.2 -> do x times per year (e.x. monthly = 12, weekly = 52, annually = 1)
#14 -> x times per year
#15 -> x times per year

timecol = [10, 21, 26, 27]

for r in range (23):
    for c in timecol:
        if data.iloc[r, c] == 'once a year' or data.iloc[r, c] == 'yearly' or data.iloc[r, c] == 'annually':
            data.iloc[r, c] = 1
        if data.iloc[r, c] == 'biannually':
            data.iloc[r, c] = 2
        if data.iloc[r, c] == '3 times per year' or data.iloc[r, c] == 'every 4 months':
            data.iloc[r, c] = 3
        if data.iloc[r, c] == '4 times per year' or data.iloc[r, c] == 'every 3 months':
            data.iloc[r, c] = 4
        if data.iloc[r, c] == '6 times per year' or data.iloc[r, c] == 'every 2 months':
            data.iloc[r, c] = 6
        if data.iloc[r, c] == 'monthly':
            data.iloc[r, c] = 12
        if data.iloc[r, c] == 'biweekly':
            data.iloc[r, c] = 26
        if data.iloc[r, c] == 'weekly':
            data.iloc[r, c] = 52
        if data.iloc[r, c] == 'daily':
            data.iloc[r, c] = 365
```
```python
#User Fee
#12.b.1 -> do amount per household per year
data['12.b.1']

#assume row 1 should be 5000 per household per year
#assume row 6 should be 5000 per hoursehold per year

data.iloc[1, 20] = '5000 per household per year'
data.iloc[6, 20] = '5000 per household per year'

for r in range(23):
    if data.iloc[r, 20][-5:] == 'month':
        data['12.b.1'] = data['12.b.1'].str.slice(0, 3)
    else:
        data['12.b.1'] = data['12.b.1'].str.slice(0, 4)
```
```python
#Convert to integers from string
data[[4, '6_women', '6_men', '6_persons-with-disabilities', 9.2, 11, '12.a.3', '12.b.1', '12.b.2', 14, 15]]
data[[4, '6_women', '6_men', '6_persons-with-disabilities', 9.2, 11, '12.a.3', '12.b.1', '12.b.2', 14, 15]] = data[[4, '6_women', '6_men', '6_persons-with-disabilities', 9.2, 11, '12.a.3', '12.b.1', '12.b.2', 14, 15]].apply(pd.to_numeric)

#User fee to annual value
for r in range(23):
    if data.iloc[r, 20] <= 4999:
        data.iloc[r, 20] = (data.iloc[r, 20]) * 12
```
At this point, the data is in a more manageable, consistent, usable form
![data-head](https://github.com/melynwhite/ISU-UP-2021-WUC-Project/blob/master/images/data-head.png)

#### Data Visualization
Steps for Descriptors & Visualization (reflection of the order of assessment):
1) Numerical Values (overview)  
2) WUC Gender Composition (Gender Ratio)  
3) Respondent Position  
4) Training & Meeting Frequency  
5) Household overview  
6) Banking system  
7) Donations  
8) Fees & Collection
9) O&M Cost; Monitoring; Repair  
10) Documentation(s)


process and many examples of code and outputs of the plots and stuff
mention difference between doing it by hand in excel versus with python (easy to copy paste and repeat)
(it'd honestly be great to create a function that would do it all... but i'm really bad at functions)
*show some plots here!*

#### Concerns
Readdressing some of those assumptions; worried that not true reflection of respondents due to the missing and assumed data
Identifying that at this point I was very worried about the text part that was coming next

### Classification & Statistics
#### Supervised Machine Learning
Wanted to practice this skill and used the naive bayes to classify if a WUC met gender ratio requirements (probs can mention that Uganda requires it)
*include code and plots*

#### Linear Regression
Wanted to create a way to determin the relationships between different pieces of information
moving forward would ideally be able to say x does or doesn't seem to relate to this other thing
general result is none so far
*include code and plots*
because of its greater relevance beyond the project, created this as my class exercise (will see later)

### Text Data
#### Cleaning & Wrangling
Go through this process
outline some code and clarify more assumptions
having to redo the excel thing again

#### Visualization
Describing what word clouds are
showing some code and *wordclouds*
not sure if the other things fit here or in other

#### Determining Relationships
isolating the data and doing the counting stuff

#### Concerns
This is difficult to reproduce because of the way I collected data, and also because of how I managed to put it into excel and python
would have to manipulate the excel file a bit, or create a completely, new one like i did before being able to do any of this stuff
wasn't really clear on text classification before and got lost in the tokenization of things, so I decided to forgo it
This isn't going to be the depth of analysis that I had originally wanted, so the pieces were carefully chosen

## Results
Question: review the project question
Answer: what the result is
### Common Challenges
maybe a thought here, maybe not
#### Different Water User Fee Amount
the code and clear result of this output

#### Different Water User Fee Collection Rate
the code and clear result of this output

### Discussion
thoughts on those results; briefly mention wanting to do more analysis but felt limited by data, knowledge, and time

### Implications
what do the results mean for ISU-UP
my suggestions on what they need to focus on
further research that should be done

## FAIR Principles
define the principles
general discussion of reproducibility
explain how my process meets the principles
explain how my process does not meet the principles

## Class Exercise
walking classmates through partial wrangling and linear regression 
because this seemed the most useful to other projects
show the code and example output from previously

from Howe: 
In each project, I'd like to see a homework assignment that the class can do/evaluate to learn more about your data.  This should be a reproducible notebook that allows them to learn one or more aspects of your data workflow.  It is also an opportunity to share your research with your colleagues.

## Project Reflection
what did I learn about my data
what did I learn from doing the project
how might i go about doing it differently
what would i have done with more time

# End


# Making the Website

This instruction is specific to the slate theme but should translate well to other themes.  You can change default variables in your website build by making changes in your `_config.yml` file:

```yml
title: [The title of your site]
description: [A short description of your site's purpose]
```

Additionally, you may choose to set the following optional variables:

```yml
show_downloads: ["true" or "false" to indicate whether to provide a download URL]
google_analytics: [Your Google Analytics tracking ID]
```
You can take a look at the `_config.yml` file in this repository to see how to type in the title and description.

### Markdown

You can see this [cheatsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) to work with Markdown language for adding features into this website.  This includes how to add headers, organization (e.g., bullets or lists), tables, and images.  It also includes how to add code to a website.

*Note that for images, you will need to place the image file in a place that it can be referenced and called.  I would suggest the github repo might be a good solution.  Often, I make an images folder and can call the raw images file.

See example [here](https://github.com/pages-themes/slate/blob/master/index.md).  You can see the raw code also.

#### Relative Links
To create links to other pages, you can read this article:  https://github.blog/2016-12-05-relative-links-for-github-pages/.  Note that these pages should by default direct to the same local folder/directory the index file is.  In this case, my README.md file is my index. If the files are in a different folder, one should specifiy the path for that folder.

### Notebooks

You can use a website to host notebooks.  First, you'll want to get the "raw" url from Github where your notebook is stored.  Then, navigate to https://nbviewer.jupyter.org and paste that URL.  The result will be a new generated URL that hosts your notebook.  This can be a [link](https://nbviewer.jupyter.org/github/isu-abe/516x/blob/master/module2/bootcamp/notebooks/nocode/Module%20IIB%20-%20Python%20Basics%20-%20no%20code.ipynb) in your website.


Here is an example of a fantastic project website:

https://stephenslab.github.io/ipynb-website/

## Advanced Features

### Stylesheet (Advanced)

If you'd like to add your own custom styles:

1. Create a file called `/assets/css/style.scss` in your site
2. Add the following content to the top of the file, exactly as shown:
    ```scss
    ---
    ---

    @import "{{ site.theme }}";
    ```
3. Add any custom CSS (or Sass, including imports) you'd like immediately after the `@import` line

*Note: If you'd like to change the theme's Sass variables, you must set new values before the `@import` line in your stylesheet.*

### Layouts (Advanced)

If you'd like to change the theme's HTML layout:

1. [Copy the original template](https://github.com/pages-themes/slate/blob/master/_layouts/default.html) from the theme's repository<br />(*Pro-tip: click "raw" to make copying easier*)
2. Create a file called `/_layouts/default.html` in your site
3. Paste the default layout content copied in the first step
4. Customize the layout as you'd like

### Overriding GitHub-generated URLs (Advanced)

Templates often rely on URLs supplied by GitHub such as links to your repository or links to download your project. If you'd like to override one or more default URLs:

1. Look at [the template source](https://github.com/pages-themes/slate/blob/master/_layouts/default.html) to determine the name of the variable. It will be in the form of `{{ site.github.zip_url }}`.
2. Specify the URL that you'd like the template to use in your site's `_config.yml`. For example, if the variable was `site.github.url`, you'd add the following:
    ```yml
    github:
      zip_url: http://example.com/download.zip
      another_url: another value
    ```
3. When your site is built, Jekyll will use the URL you specified, rather than the default one provided by GitHub.

*Note: You must remove the `site.` prefix, and each variable name (after the `github.`) should be indent with two space below `github:`.*

For more information, see [the Jekyll variables documentation](https://jekyllrb.com/docs/variables/).
